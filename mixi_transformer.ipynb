{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled46.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HisakaKoji/bert-japanese/blob/master/mixi_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzMAJZB4GiM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ce7230e9-3cdf-4f85-c7c4-91107c6947ad"
      },
      "source": [
        "!git clone https://github.com/halhorn/deep_dialog_tutorial.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep_dialog_tutorial'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Total 132 (delta 0), reused 0 (delta 0), pack-reused 132\u001b[K\n",
            "Receiving objects: 100% (132/132), 3.51 MiB | 19.04 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5vBifZEHmnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c660ee99-085e-47f0-b062-c6e3df0bd9b8"
      },
      "source": [
        "%cd deep_dialog_tutorial\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep_dialog_tutorial\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmVfx-5PHv5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14a3ed64-ced3-47f8-97d5-b0d465296324"
      },
      "source": [
        "# カレントディレクトリをリポジトリ直下にするおまじない\n",
        "import os\n",
        "while os.getcwd().split('/')[-1] != 'deep_dialog_tutorial': os.chdir('..')\n",
        "print('current dir:', os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current dir: /content/deep_dialog_tutorial\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xifE44n9H447",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "a22f741d-b293-4cce-fba8-a4a74654fe32"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 4.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNEm7TqdHyvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from deepdialog.transformer.transformer import Transformer\n",
        "from deepdialog.transformer.preprocess.batch_generator import BatchGenerator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3oo_2yMH-K9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'data/natsume.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boozRUOpIEGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_generator = BatchGenerator()\n",
        "batch_generator.load(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0r-LHpzIG0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = batch_generator.vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz75VKUgIJU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "36cdf004-0b37-4a3e-9e7e-2c9a1d81543d"
      },
      "source": [
        "\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    transformer = Transformer(\n",
        "        vocab_size=vocab_size,\n",
        "        hopping_num=4,\n",
        "        head_num=8,\n",
        "        hidden_dim=512,\n",
        "        dropout_rate=0.1,\n",
        "        max_length=50,\n",
        "    )\n",
        "    transformer.build_graph()\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0831 05:26:24.491544 139682951456640 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0831 05:26:24.589937 139682951456640 deprecation_wrapper.py:119] From /content/deep_dialog_tutorial/deepdialog/transformer/transformer.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0831 05:26:24.617337 139682951456640 deprecation_wrapper.py:119] From /content/deep_dialog_tutorial/deepdialog/transformer/transformer.py:111: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
            "\n",
            "W0831 05:26:25.082098 139682951456640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0831 05:26:25.525223 139682951456640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "W0831 05:26:30.335272 139682951456640 deprecation_wrapper.py:119] From /content/deep_dialog_tutorial/deepdialog/transformer/metrics.py:35: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0831 05:26:30.355439 139682951456640 deprecation_wrapper.py:119] From /content/deep_dialog_tutorial/deepdialog/transformer/metrics.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0831 05:26:30.378386 139682951456640 deprecation.py:323] From /content/deep_dialog_tutorial/deepdialog/transformer/metrics.py:48: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqjEfRDxIM0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_dir = 'tmp/learning/transformer/'\n",
        "log_dir = os.path.join(save_dir, 'log')\n",
        "ckpt_path = os.path.join(save_dir, 'checkpoints/model.ckpt')\n",
        "\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UacgBQsCIQQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "    global_step = tf.train.get_or_create_global_step()\n",
        "    \n",
        "    learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n",
        "    optimizer = tf.train.AdamOptimizer(\n",
        "        learning_rate=learning_rate,\n",
        "        beta2=0.98,\n",
        "    )\n",
        "    optimize_op = optimizer.minimize(transformer.loss, global_step=global_step)\n",
        "\n",
        "    summary_op = tf.summary.merge([\n",
        "        tf.summary.scalar('train/loss', transformer.loss),\n",
        "        tf.summary.scalar('train/acc', transformer.acc),\n",
        "        tf.summary.scalar('train/learning_rate', learning_rate),\n",
        "    ], name='train_summary')\n",
        "    summary_writer = tf.summary.FileWriter(log_dir, graph)\n",
        "    saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_WOPW1SITk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_step = 100000\n",
        "batch_size = 128\n",
        "max_learning_rate = 0.0001\n",
        "warmup_step = 4000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDEY3B9gIWHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_learning_rate(step: int) -> float:\n",
        "    rate = min(step ** -0.5, step * warmup_step ** -1.5) / warmup_step ** -0.5\n",
        "    return max_learning_rate * rate\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hEWxydnIYaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    step = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssjzROwiIbAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fb94a80-6dbe-4f8d-a158-852f39e16219"
      },
      "source": [
        "with graph.as_default():\n",
        "    for batch in batch_generator.get_batch(batch_size=batch_size):\n",
        "        feed = {\n",
        "            **batch,\n",
        "            learning_rate: get_learning_rate(step + 1),\n",
        "        }\n",
        "        _, loss, acc, step, summary = sess.run([optimize_op, transformer.loss, transformer.acc, global_step, summary_op], feed_dict=feed)\n",
        "        summary_writer.add_summary(summary, step)\n",
        "        \n",
        "        if step % 100 == 0:\n",
        "            print(f'{step}: loss: {loss},\\t acc: {acc}')\n",
        "            saver.save(sess, ckpt_path, global_step=step)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: loss: 8.36015796661377,\t acc: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}