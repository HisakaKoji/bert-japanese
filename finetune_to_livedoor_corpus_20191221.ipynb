{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune-to-livedoor-corpus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HisakaKoji/bert-japanese/blob/master/finetune_to_livedoor_corpus_20191221.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHAWaTz6qRZP",
        "colab_type": "text"
      },
      "source": [
        "# Finetuning of the pretrained Japanese BERT model\n",
        "\n",
        "Finetune the pretrained model to solve multi-class classification problems.  \n",
        "This notebook requires the following objects:\n",
        "- trained sentencepiece model (model and vocab files)\n",
        "- pretraiend Japanese BERT model\n",
        "\n",
        "Dataset is livedoor ニュースコーパス in https://www.rondhuit.com/download.html.  \n",
        "We make test:dev:train = 2:2:6 datasets.\n",
        "\n",
        "**This colab notebook assumes the above models are stored on some GSC bucket you can acess its objects.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itGKrh8YqV2j",
        "colab_type": "code",
        "outputId": "b46d4cb3-e30a-4036-b42d-7d13829c87f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!git clone --recursive https://github.com/HisakaKoji/bert-japanese.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert-japanese'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/18)\u001b[K\rremote: Counting objects:  11% (2/18)\u001b[K\rremote: Counting objects:  16% (3/18)\u001b[K\rremote: Counting objects:  22% (4/18)\u001b[K\rremote: Counting objects:  27% (5/18)\u001b[K\rremote: Counting objects:  33% (6/18)\u001b[K\rremote: Counting objects:  38% (7/18)\u001b[K\rremote: Counting objects:  44% (8/18)\u001b[K\rremote: Counting objects:  50% (9/18)\u001b[K\rremote: Counting objects:  55% (10/18)\u001b[K\rremote: Counting objects:  61% (11/18)\u001b[K\rremote: Counting objects:  66% (12/18)\u001b[K\rremote: Counting objects:  72% (13/18)\u001b[K\rremote: Counting objects:  77% (14/18)\u001b[K\rremote: Counting objects:  83% (15/18)\u001b[K\rremote: Counting objects:  88% (16/18)\u001b[K\rremote: Counting objects:  94% (17/18)\u001b[K\rremote: Counting objects: 100% (18/18)\u001b[K\rremote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects:   6% (1/15)\u001b[K\rremote: Compressing objects:  13% (2/15)\u001b[K\rremote: Compressing objects:  20% (3/15)\u001b[K\rremote: Compressing objects:  26% (4/15)\u001b[K\rremote: Compressing objects:  33% (5/15)\u001b[K\rremote: Compressing objects:  40% (6/15)\u001b[K\rremote: Compressing objects:  46% (7/15)\u001b[K\rremote: Compressing objects:  53% (8/15)\u001b[K\rremote: Compressing objects:  60% (9/15)\u001b[K\rremote: Compressing objects:  66% (10/15)\u001b[K\rremote: Compressing objects:  73% (11/15)\u001b[K\rremote: Compressing objects:  80% (12/15)\u001b[K\rremote: Compressing objects:  86% (13/15)\u001b[K\rremote: Compressing objects:  93% (14/15)\u001b[K\rremote: Compressing objects: 100% (15/15)\u001b[K\rremote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "Receiving objects:   0% (1/274)   \rReceiving objects:   1% (3/274)   \rReceiving objects:   2% (6/274)   \rReceiving objects:   3% (9/274)   \rReceiving objects:   4% (11/274)   \rReceiving objects:   5% (14/274)   \rReceiving objects:   6% (17/274)   \rReceiving objects:   7% (20/274)   \rReceiving objects:   8% (22/274)   \rReceiving objects:   9% (25/274)   \rReceiving objects:  10% (28/274)   \rReceiving objects:  11% (31/274)   \rReceiving objects:  12% (33/274)   \rReceiving objects:  13% (36/274)   \rReceiving objects:  14% (39/274)   \rReceiving objects:  15% (42/274)   \rReceiving objects:  16% (44/274)   \rReceiving objects:  17% (47/274)   \rReceiving objects:  18% (50/274)   \rReceiving objects:  19% (53/274)   \rReceiving objects:  20% (55/274)   \rReceiving objects:  21% (58/274)   \rReceiving objects:  22% (61/274)   \rReceiving objects:  23% (64/274)   \rReceiving objects:  24% (66/274)   \rReceiving objects:  25% (69/274)   \rReceiving objects:  26% (72/274)   \rReceiving objects:  27% (74/274)   \rReceiving objects:  28% (77/274)   \rReceiving objects:  29% (80/274)   \rReceiving objects:  30% (83/274)   \rReceiving objects:  31% (85/274)   \rReceiving objects:  32% (88/274)   \rReceiving objects:  33% (91/274)   \rReceiving objects:  34% (94/274)   \rReceiving objects:  35% (96/274)   \rReceiving objects:  36% (99/274)   \rReceiving objects:  37% (102/274)   \rReceiving objects:  38% (105/274)   \rReceiving objects:  39% (107/274)   \rReceiving objects:  40% (110/274)   \rReceiving objects:  41% (113/274)   \rReceiving objects:  42% (116/274)   \rReceiving objects:  43% (118/274)   \rReceiving objects:  44% (121/274)   \rReceiving objects:  45% (124/274)   \rReceiving objects:  46% (127/274)   \rReceiving objects:  47% (129/274)   \rReceiving objects:  48% (132/274)   \rReceiving objects:  49% (135/274)   \rReceiving objects:  50% (137/274)   \rReceiving objects:  51% (140/274)   \rReceiving objects:  52% (143/274)   \rReceiving objects:  53% (146/274)   \rReceiving objects:  54% (148/274)   \rReceiving objects:  55% (151/274)   \rReceiving objects:  56% (154/274)   \rReceiving objects:  57% (157/274)   \rReceiving objects:  58% (159/274)   \rReceiving objects:  59% (162/274)   \rReceiving objects:  60% (165/274)   \rReceiving objects:  61% (168/274)   \rReceiving objects:  62% (170/274)   \rReceiving objects:  63% (173/274)   \rReceiving objects:  64% (176/274)   \rReceiving objects:  65% (179/274)   \rReceiving objects:  66% (181/274)   \rReceiving objects:  67% (184/274)   \rReceiving objects:  68% (187/274)   \rReceiving objects:  69% (190/274)   \rReceiving objects:  70% (192/274)   \rReceiving objects:  71% (195/274)   \rReceiving objects:  72% (198/274)   \rReceiving objects:  73% (201/274)   \rReceiving objects:  74% (203/274)   \rReceiving objects:  75% (206/274)   \rReceiving objects:  76% (209/274)   \rReceiving objects:  77% (211/274)   \rReceiving objects:  78% (214/274)   \rReceiving objects:  79% (217/274)   \rReceiving objects:  80% (220/274)   \rReceiving objects:  81% (222/274)   \rReceiving objects:  82% (225/274)   \rReceiving objects:  83% (228/274)   \rReceiving objects:  84% (231/274)   \rReceiving objects:  85% (233/274)   \rReceiving objects:  86% (236/274)   \rReceiving objects:  87% (239/274)   \rReceiving objects:  88% (242/274)   \rReceiving objects:  89% (244/274)   \rReceiving objects:  90% (247/274)   \rReceiving objects:  91% (250/274)   \rReceiving objects:  92% (253/274)   \rReceiving objects:  93% (255/274)   \rReceiving objects:  94% (258/274)   \rReceiving objects:  95% (261/274)   \rremote: Total 274 (delta 7), reused 7 (delta 3), pack-reused 256\u001b[K\n",
            "Receiving objects:  96% (264/274)   \rReceiving objects:  97% (266/274)   \rReceiving objects:  98% (269/274)   \rReceiving objects:  99% (272/274)   \rReceiving objects: 100% (274/274)   \rReceiving objects: 100% (274/274), 435.20 KiB | 5.51 MiB/s, done.\n",
            "Resolving deltas:   0% (0/162)   \rResolving deltas:   6% (11/162)   \rResolving deltas:   9% (16/162)   \rResolving deltas:  10% (17/162)   \rResolving deltas:  11% (18/162)   \rResolving deltas:  14% (24/162)   \rResolving deltas:  16% (26/162)   \rResolving deltas:  19% (32/162)   \rResolving deltas:  20% (34/162)   \rResolving deltas:  23% (38/162)   \rResolving deltas:  24% (40/162)   \rResolving deltas:  25% (41/162)   \rResolving deltas:  59% (96/162)   \rResolving deltas:  65% (106/162)   \rResolving deltas:  67% (110/162)   \rResolving deltas:  68% (111/162)   \rResolving deltas:  85% (138/162)   \rResolving deltas:  91% (149/162)   \rResolving deltas:  94% (153/162)   \rResolving deltas:  98% (159/162)   \rResolving deltas:  99% (161/162)   \rResolving deltas: 100% (162/162)   \rResolving deltas: 100% (162/162), done.\n",
            "Submodule 'bert' (https://github.com/google-research/bert.git) registered for path 'bert'\n",
            "Cloning into '/content/bert-japanese/bert'...\n",
            "remote: Enumerating objects: 336, done.        \n",
            "remote: Total 336 (delta 0), reused 0 (delta 0), pack-reused 336        \n",
            "Receiving objects: 100% (336/336), 291.40 KiB | 3.94 MiB/s, done.\n",
            "Resolving deltas: 100% (184/184), done.\n",
            "Submodule path 'bert': checked out '88a817c37f788702a363ff935fd173b6dc6ac0d6'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOuxLMPitaGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b779a4f-c668-419e-b6cd-ea8ed336963e"
      },
      "source": [
        "!pip install -q -r bert-japanese/requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 3.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_VWV70FrqfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "223b9368-8369-4c03-90ef-e86c473cb9a0"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkXFpbm2qfj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd bert-japanese/notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWbKTBu4s8-r",
        "colab_type": "code",
        "outputId": "3a12b0b0-5b2c-4173-b1a2-9979fc9a744b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!gsutil cp gs://hisaka/model/wiki-ja.model ../model/\n",
        "!gsutil cp gs://hisaka/model/wiki-ja.vocab ../model/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://hisaka/model/wiki-ja.model...\n",
            "/ [0 files][    0.0 B/786.8 KiB]                                                \rSkipping attempt to download to filename ending with slash\n",
            "(../model/). This typically happens when using gsutil to download from\n",
            "a subdirectory created by the Cloud Console\n",
            "(https://cloud.google.com/console)\n",
            "\n",
            "Operation completed over 1 objects/786.8 KiB.                                    \n",
            "Copying gs://hisaka/model/wiki-ja.vocab...\n",
            "Skipping attempt to download to filename ending with slash\n",
            "(../model/). This typically happens when using gsutil to download from\n",
            "a subdirectory created by the Cloud Console\n",
            "(https://cloud.google.com/console)\n",
            "\n",
            "Operation completed over 1 objects/581.7 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CBPzOAHqeQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFh6h8lzqb8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4VOeMEKqgMz",
        "colab_type": "code",
        "outputId": "5ce3ed69-7a15-43f6-f297-e6703afcab59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check-extract-features.ipynb       finetune-to-livedoor-corpus.ipynb\n",
            "check-trained-tokenizer.ipynb      pretraining.ipynb\n",
            "finetune_to_livedoor_corpus.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZBoDKTsGdwa",
        "colab_type": "text"
      },
      "source": [
        "Check TPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiTrQvdWrxzR",
        "colab_type": "code",
        "outputId": "0f092e0e-5b26-4de6-8b85-44ff1864656a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.10.32.186:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 8910512275326473485),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11773703224333706244),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6186601395256151883),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 3303954787010643963),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17467741895312789961),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6552579700939112602),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8862163762629197284),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12729527184096945373),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 11195908215802012460),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5774106020315271026),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 961216465026310598)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fIdKMrDqRZX",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "You need to put preprocessed data on your GCS bucket.  \n",
        "To create preprocessed data, follow https://github.com/yoheikikuta/bert-japanese/blob/master/notebook/finetune-to-livedoor-corpus.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mly_p24NqRaH",
        "colab_type": "text"
      },
      "source": [
        "## Finetune pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmZaLO0OLeOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_PATH = 'gs://hisaka/model/model.ckpt-1400000'  # GCS bucket\n",
        "PRETRAINED_MODEL_PATH = 'gs://hisaka/rurubu/output/model.ckpt-419'  # GCS bucket\n",
        "INPUT_DATA_GCS = 'gs://hisaka/rurubu'  # GCS bucket\n",
        "FINETUNE_OUTPUT_DIR = 'gs://hisaka/rurubu/output1219' # GCS bucket"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s07N5EWqRaN",
        "colab_type": "code",
        "outputId": "38e3bdfe-4b31-47ae-899a-181452623cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "source": [
        "%%time\n",
        "!python3 ../src/run_classifier.py \\\n",
        "  --task_name=livedoor \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --do_train=true \\\n",
        "  --do_eval=true \\\n",
        "  --data_dir={INPUT_DATA_GCS} \\\n",
        "  --model_file=../model/wiki-ja.model \\\n",
        "  --vocab_file=../model/wiki-ja.vocab \\\n",
        "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
        "  --max_seq_length=512 \\\n",
        "  --train_batch_size=64 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --num_train_epochs=10.0 \\\n",
        "  --output_dir={FINETUNE_OUTPUT_DIR}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert-japanese/src/../bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/run_classifier.py:856: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/run_classifier.py:661: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1221 08:53:28.881185 139846685403008 module_wrapper.py:139] From ../src/run_classifier.py:661: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/run_classifier.py:661: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1221 08:53:28.881370 139846685403008 module_wrapper.py:139] From ../src/run_classifier.py:661: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert-japanese/src/../bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1221 08:53:28.881757 139846685403008 module_wrapper.py:139] From /content/bert-japanese/src/../bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/run_classifier.py:682: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1221 08:53:28.882394 139846685403008 module_wrapper.py:139] From ../src/run_classifier.py:682: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"../src/run_classifier.py\", line 856, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"../src/run_classifier.py\", line 695, in main\n",
            "    do_lower_case=FLAGS.do_lower_case)\n",
            "  File \"/content/bert-japanese/src/tokenization_sentencepiece.py\", line 152, in __init__\n",
            "    self.tokenizer = SentencePieceTokenizer(model_file, do_lower_case=do_lower_case)\n",
            "  File \"/content/bert-japanese/src/tokenization_sentencepiece.py\", line 175, in __init__\n",
            "    if self.tokenizer.Load(model_file):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sentencepiece.py\", line 118, in Load\n",
            "    return _sentencepiece.SentencePieceProcessor_Load(self, filename)\n",
            "OSError: Not found: \"../model/wiki-ja.model\": No such file or directory Error #2\n",
            "CPU times: user 45.7 ms, sys: 9.36 ms, total: 55 ms\n",
            "Wall time: 5.37 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhEPDllLqRaU",
        "colab_type": "text"
      },
      "source": [
        "## Predict using the finetuned model\n",
        "\n",
        "Let's predict test data using the finetuned model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYmG1srRxT7U",
        "colab_type": "code",
        "outputId": "48990bc5-6578-4611-8895-899ebf08100e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "source": [
        "%%time\n",
        "!python3 ../src/run_classifier.py \\\n",
        "  --task_name=livedoor \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --do_train=false \\\n",
        "  --do_eval=false \\\n",
        "  --do_predict=true \\\n",
        "  --data_dir={INPUT_DATA_GCS} \\\n",
        "  --model_file=../model/wiki-ja.model \\\n",
        "  --vocab_file=../model/wiki-ja.vocab \\\n",
        "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
        "  --max_seq_length=512 \\\n",
        "  --train_batch_size=64 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --num_train_epochs=3.0 \\\n",
        "  --output_dir={FINETUNE_OUTPUT_DIR}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert-japanese/src/../bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/run_classifier.py:856: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/run_classifier.py:661: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1221 08:53:34.064945 140251556906880 module_wrapper.py:139] From ../src/run_classifier.py:661: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/run_classifier.py:661: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1221 08:53:34.065144 140251556906880 module_wrapper.py:139] From ../src/run_classifier.py:661: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert-japanese/src/../bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1221 08:53:34.065570 140251556906880 module_wrapper.py:139] From /content/bert-japanese/src/../bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/run_classifier.py:682: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1221 08:53:34.066337 140251556906880 module_wrapper.py:139] From ../src/run_classifier.py:682: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"../src/run_classifier.py\", line 856, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"../src/run_classifier.py\", line 695, in main\n",
            "    do_lower_case=FLAGS.do_lower_case)\n",
            "  File \"/content/bert-japanese/src/tokenization_sentencepiece.py\", line 152, in __init__\n",
            "    self.tokenizer = SentencePieceTokenizer(model_file, do_lower_case=do_lower_case)\n",
            "  File \"/content/bert-japanese/src/tokenization_sentencepiece.py\", line 175, in __init__\n",
            "    if self.tokenizer.Load(model_file):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sentencepiece.py\", line 118, in Load\n",
            "    return _sentencepiece.SentencePieceProcessor_Load(self, filename)\n",
            "OSError: Not found: \"../model/wiki-ja.model\": No such file or directory Error #2\n",
            "CPU times: user 45.9 ms, sys: 7.96 ms, total: 53.8 ms\n",
            "Wall time: 5.17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKA6AgKZE6jg",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bCQcYvoDLaw",
        "colab_type": "text"
      },
      "source": [
        "Download result and original data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLYcxd1ox5bq",
        "colab_type": "code",
        "outputId": "3f846841-8f89-44f2-ae6a-0fd7ba52ce3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!gsutil cp {FINETUNE_OUTPUT_DIR}/test_results.tsv .\n",
        "!gsutil cp {INPUT_DATA_GCS}/train.tsv .\n",
        "!gsutil cp {INPUT_DATA_GCS}/dev.tsv .\n",
        "!gsutil cp {INPUT_DATA_GCS}/test.tsv ."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://hisaka/rurubu/output1219/test_results.tsv...\n",
            "/ [1 files][395.1 KiB/395.1 KiB]                                                \n",
            "Operation completed over 1 objects/395.1 KiB.                                    \n",
            "Copying gs://hisaka/rurubu/train.tsv...\n",
            "/ [1 files][  1.2 MiB/  1.2 MiB]                                                \n",
            "Operation completed over 1 objects/1.2 MiB.                                      \n",
            "Copying gs://hisaka/rurubu/dev.tsv...\n",
            "/ [1 files][408.5 KiB/408.5 KiB]                                                \n",
            "Operation completed over 1 objects/408.5 KiB.                                    \n",
            "Copying gs://hisaka/rurubu/test.tsv...\n",
            "/ [1 files][398.3 KiB/398.3 KiB]                                                \n",
            "Operation completed over 1 objects/398.3 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZAuB7s0Dbo2",
        "colab_type": "text"
      },
      "source": [
        "### Trained model\n",
        "\n",
        "Check accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhoM3SJ0Js1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weZ9KlSXgGCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "06cfa436-c9c9-4842-9ce0-b13ec4b4eb49"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"../src\")\n",
        "\n",
        "from run_classifier import LivedoorProcessor\n",
        "\n",
        "processor = LivedoorProcessor()\n",
        "label_list = processor.get_labels()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert-japanese/src/../bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CRVqy_SOSZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list = ['Traditional-Festivalsand-annual-events' , 'Traditional-Festivalsand-annual-events'  , 'Traditional-performing-arts-and-dance' ,'festival' ,'food'   ,'festival'   , \\\n",
        "          'flower-nature'   ,'festival'   ,'fireworks'   ,'snow'  ,'illumination'  ,'music'  ,'sports'  ,'museum'  ,'museum'  ,'festival'  ,'festival'  ,'experience'  ,  \\\n",
        "           'school'  ,'talk'  ,'stage'  ,'animal-fish-park'  ,'animal-fish-park'  ,'anniversary'  ,'fair'  ,'other'  ,'Industry'  ,'festival'  ,'festival' ,'other']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhccEqvTx5nO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.read_csv(\"./test_results.tsv\", sep='\\t', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn-IKJrtx5sB",
        "colab_type": "code",
        "outputId": "f05c667c-4449-4689-9492-b4d31ce84677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "result.head(2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.998055</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.000323</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>0.989966</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.002022</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000810</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        27        28        29\n",
              "0  0.000069  0.000048  0.000019  ...  0.000044  0.000046  0.000039\n",
              "1  0.000158  0.000185  0.000323  ...  0.000204  0.000147  0.000153\n",
              "\n",
              "[2 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T4jup_cqRa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(\"./test.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4OXFJd4N9sy",
        "colab_type": "code",
        "outputId": "816ae2bc-97b5-4ea1-fd37-6ff5cca01068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "label_list"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Traditional-Festivalsand-annual-events',\n",
              " 'Traditional-Festivalsand-annual-events',\n",
              " 'Traditional-performing-arts-and-dance',\n",
              " 'festival',\n",
              " 'food',\n",
              " 'festival',\n",
              " 'flower-nature',\n",
              " 'festival',\n",
              " 'fireworks',\n",
              " 'snow',\n",
              " 'illumination',\n",
              " 'music',\n",
              " 'sports',\n",
              " 'museum',\n",
              " 'museum',\n",
              " 'festival',\n",
              " 'festival',\n",
              " 'experience',\n",
              " 'school',\n",
              " 'talk',\n",
              " 'stage',\n",
              " 'animal-fish-park',\n",
              " 'animal-fish-park',\n",
              " 'anniversary',\n",
              " 'fair',\n",
              " 'other',\n",
              " 'Industry',\n",
              " 'festival',\n",
              " 'festival',\n",
              " 'other']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awsr4Uk9qRa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['predict'] = [ label_list[np.array(elem[1]).argmax()] for elem in result.iterrows() ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsKCv67CqRa-",
        "colab_type": "code",
        "outputId": "acde27cd-b67d-42cb-eaab-e979f51f8357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8303393213572854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKPg0BYtwDO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPofIal0qRbA",
        "colab_type": "text"
      },
      "source": [
        "A littel more detailed check using `sklearn.metrics`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWB0hihAqRbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfLBM1QaqRbK",
        "colab_type": "code",
        "outputId": "3e408a5e-f0b9-4eee-965b-6ecbdcbf7aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "print(classification_report(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                        precision    recall  f1-score   support\n",
            "\n",
            "                              Industry       0.70      0.59      0.64        27\n",
            "Traditional-Festivalsand-annual-events       0.88      0.88      0.88       320\n",
            " Traditional-performing-arts-and-dance       0.76      0.73      0.74        70\n",
            "                           anniversary       0.00      0.00      0.00         1\n",
            "                            experience       0.78      0.82      0.80        17\n",
            "                                  fair       0.00      0.00      0.00         1\n",
            "                              festival       0.58      0.62      0.60       104\n",
            "                             fireworks       0.91      0.96      0.94       100\n",
            "                         flower-nature       0.95      0.94      0.94       152\n",
            "                                  food       0.77      0.83      0.80        24\n",
            "                          illumination       0.90      0.95      0.92        92\n",
            "                                museum       0.00      0.00      0.00         1\n",
            "                                 music       0.75      0.90      0.82        20\n",
            "                                 other       0.56      0.32      0.41        31\n",
            "                                  snow       0.78      0.74      0.76        19\n",
            "                                sports       0.67      0.74      0.70        19\n",
            "                                 stage       1.00      0.50      0.67         2\n",
            "                                  talk       1.00      0.50      0.67         2\n",
            "\n",
            "                              accuracy                           0.83      1002\n",
            "                             macro avg       0.67      0.61      0.63      1002\n",
            "                          weighted avg       0.83      0.83      0.83      1002\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqQJCOJvwIbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# print(classification_report(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ilx2v3_qRbN",
        "colab_type": "code",
        "outputId": "16c443cb-61a8-4486-fa2f-4068bb37b72d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "print(confusion_matrix(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 16   1   0   0   0   0   6   0   0   2   0   1   0   1   0   0   0   0]\n",
            " [  0 283  10   0   1   0  18   3   3   1   1   0   0   0   0   0   0   0]\n",
            " [  1  11  51   0   0   0   5   1   0   0   0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0  14   0   0   0   0   0   0   0   2   0   0   1   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2  15   4   1   0   0  64   4   5   2   2   0   3   1   0   1   0   0]\n",
            " [  0   1   0   0   0   0   2  96   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0   3   1   0   0   0   2   0 143   0   1   0   0   0   0   2   0   0]\n",
            " [  2   0   0   0   0   0   2   0   0  20   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0  87   0   0   3   1   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0   0   0   0   0  18   0   0   0   0   0]\n",
            " [  0   4   1   0   0   0   6   0   0   1   4   0   0  10   2   3   0   0]\n",
            " [  0   0   0   0   0   0   2   1   0   0   1   0   0   1  14   0   0   0]\n",
            " [  0   2   0   0   2   0   0   0   0   0   0   0   0   0   1  14   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uclnr666wKNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# print(confusion_matrix(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B05vo5fHO6dT",
        "colab_type": "code",
        "outputId": "bda5cc27-6697-4ea8-f8ae-6ce669851c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check-extract-features.ipynb\t   pretraining.ipynb\n",
            "check-trained-tokenizer.ipynb\t   test_results.tsv\n",
            "dev.tsv\t\t\t\t   test.tsv\n",
            "finetune_to_livedoor_corpus.ipynb  train.tsv\n",
            "finetune-to-livedoor-corpus.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FjTB439N3lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.to_csv('../test20191221.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWssuGyMPt8L",
        "colab_type": "code",
        "outputId": "b37c635e-3b1c-4048-b9b2-5ab1e6e65f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!gsutil cp -r  test20191221.csv  gs://hisaka/20191220 "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CommandException: No URLs matched: test20191221.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNGkY-KRqRbS",
        "colab_type": "text"
      },
      "source": [
        "### Simple baseline model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGt3notoqRbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7bqEUJuqRbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"./train.tsv\", sep='\\t')\n",
        "dev_df = pd.read_csv(\"./dev.tsv\", sep='\\t')\n",
        "test_df = pd.read_csv(\"./test.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyq6TzksqRbV",
        "colab_type": "code",
        "outputId": "0b48e682-1473-4d40-bb81-4317a0d2e646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get -q install -y mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libmecab2 mecab-utils\n",
            "The following NEW packages will be installed:\n",
            "  libmecab-dev libmecab2 mecab mecab-ipadic mecab-ipadic-utf8 mecab-utils\n",
            "0 upgraded, 6 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 12.8 MB of archives.\n",
            "After this operation, 60.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 12.8 MB in 1s (8,702 kB/s)\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "(Reading database ... 135004 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../1-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../2-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../3-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../4-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../5-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPFpytOMqRbY",
        "colab_type": "code",
        "outputId": "6487a4cd-1b68-4711-d4a9-fd516435d427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install -q mecab-python3==0.7"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▉                        | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25h  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llc5aXZvqRbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import MeCab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CSVpKjqqRbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = MeCab.Tagger(\"-Owakati\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDv-JvWNqRbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dev_df = pd.concat([train_df, dev_df])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW1QDtRmqRbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dev_xs = train_dev_df['text'].apply(lambda x: m.parse(x))\n",
        "train_dev_ys = train_dev_df['label']\n",
        "\n",
        "test_xs = test_df['text'].apply(lambda x: m.parse(x))\n",
        "test_ys = test_df['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwdR0UwoqRbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=750)\n",
        "train_dev_xs_ = vectorizer.fit_transform(train_dev_xs)\n",
        "test_xs_ = vectorizer.transform(test_xs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P5zw9RdE0qX",
        "colab_type": "text"
      },
      "source": [
        "The following set up is not exactly identical to that of BERT because inside Classifier it uses `train_test_split` with shuffle.  \n",
        "In addition, parameters are not well tuned, however, we think it's enough to check the power of BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ_qr_Bzwea8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "model = GradientBoostingClassifier(n_estimators=200,\n",
        "                                   validation_fraction=len(dev_df)/len(train_df),\n",
        "                                   n_iter_no_change=5,\n",
        "                                   tol=0.01,\n",
        "                                   random_state=23)\n",
        "\n",
        "### 1/5 of full training data.\n",
        "# model = GradientBoostingClassifier(n_estimators=200,\n",
        "#                                    validation_fraction=len(train_df)/len(dev_df),\n",
        "#                                    n_iter_no_change=5,\n",
        "#                                    tol=0.01,\n",
        "#                                    random_state=23)\n",
        "\n",
        "model.fit(train_dev_xs_, train_dev_ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQLcNADBqRbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqKLsXi6wsSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# print(classification_report(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsDhUVhKqRb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgQYajIXwtwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# print(confusion_matrix(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2IdnG6mqRb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}