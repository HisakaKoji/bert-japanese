{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune-to-livedoor-corpus.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HisakaKoji/bert-japanese/blob/master/notebook/finetune_to_livedoor_corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHAWaTz6qRZP",
        "colab_type": "text"
      },
      "source": [
        "# Finetuning of the pretrained Japanese BERT model\n",
        "\n",
        "Finetune the pretrained model to solve multi-class classification problems.  \n",
        "This notebook requires the following objects:\n",
        "- trained sentencepiece model (model and vocab files)\n",
        "- pretraiend Japanese BERT model\n",
        "\n",
        "Dataset is livedoor ニュースコーパス in https://www.rondhuit.com/download.html.  \n",
        "We make test:dev:train = 2:2:6 datasets.\n",
        "\n",
        "**This colab notebook assumes the above models are stored on some GSC bucket you can acess its objects.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjgRv0s6DgMt",
        "colab_type": "code",
        "outputId": "93af01e1-f65c-4c4f-b6f3-0cd64b321e43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuVk-s7tB-NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%rm -rf bert-japanese"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itGKrh8YqV2j",
        "colab_type": "code",
        "outputId": "6cd00df1-ebbf-42c5-9a06-7a1498c733c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!git clone  https://github.com/HisakaKoji/bert-japanese.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert-japanese'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/22)\u001b[K\rremote: Counting objects:   9% (2/22)\u001b[K\rremote: Counting objects:  13% (3/22)\u001b[K\rremote: Counting objects:  18% (4/22)\u001b[K\rremote: Counting objects:  22% (5/22)\u001b[K\rremote: Counting objects:  27% (6/22)\u001b[K\rremote: Counting objects:  31% (7/22)\u001b[K\rremote: Counting objects:  36% (8/22)\u001b[K\rremote: Counting objects:  40% (9/22)\u001b[K\rremote: Counting objects:  45% (10/22)\u001b[K\rremote: Counting objects:  50% (11/22)\u001b[K\rremote: Counting objects:  54% (12/22)\u001b[K\rremote: Counting objects:  59% (13/22)\u001b[K\rremote: Counting objects:  63% (14/22)\u001b[K\rremote: Counting objects:  68% (15/22)\u001b[K\rremote: Counting objects:  72% (16/22)\u001b[K\rremote: Counting objects:  77% (17/22)\u001b[K\rremote: Counting objects:  81% (18/22)\u001b[K\rremote: Counting objects:  86% (19/22)\u001b[K\rremote: Counting objects:  90% (20/22)\u001b[K\rremote: Counting objects:  95% (21/22)\u001b[K\rremote: Counting objects: 100% (22/22)\u001b[K\rremote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects:   5% (1/19)\u001b[K\rremote: Compressing objects:  10% (2/19)\u001b[K\rremote: Compressing objects:  15% (3/19)\u001b[K\rremote: Compressing objects:  21% (4/19)\u001b[K\rremote: Compressing objects:  26% (5/19)\u001b[K\rremote: Compressing objects:  31% (6/19)\u001b[K\rremote: Compressing objects:  36% (7/19)\u001b[K\rremote: Compressing objects:  42% (8/19)\u001b[K\rremote: Compressing objects:  47% (9/19)\u001b[K\rremote: Compressing objects:  52% (10/19)\u001b[K\rremote: Compressing objects:  57% (11/19)\u001b[K\rremote: Compressing objects:  63% (12/19)\u001b[K\rremote: Compressing objects:  68% (13/19)\u001b[K\rremote: Compressing objects:  73% (14/19)\u001b[K\rremote: Compressing objects:  78% (15/19)\u001b[K\rremote: Compressing objects:  84% (16/19)\u001b[K\rremote: Compressing objects:  89% (17/19)\u001b[K\rremote: Compressing objects:  94% (18/19)\u001b[K\rremote: Compressing objects: 100% (19/19)\u001b[K\rremote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "Receiving objects:   0% (1/148)   \rReceiving objects:   1% (2/148)   \rReceiving objects:   2% (3/148)   \rReceiving objects:   3% (5/148)   \rReceiving objects:   4% (6/148)   \rReceiving objects:   5% (8/148)   \rReceiving objects:   6% (9/148)   \rReceiving objects:   7% (11/148)   \rReceiving objects:   8% (12/148)   \rReceiving objects:   9% (14/148)   \rReceiving objects:  10% (15/148)   \rReceiving objects:  11% (17/148)   \rReceiving objects:  12% (18/148)   \rReceiving objects:  13% (20/148)   \rReceiving objects:  14% (21/148)   \rReceiving objects:  15% (23/148)   \rReceiving objects:  16% (24/148)   \rReceiving objects:  17% (26/148)   \rReceiving objects:  18% (27/148)   \rReceiving objects:  19% (29/148)   \rReceiving objects:  20% (30/148)   \rReceiving objects:  21% (32/148)   \rReceiving objects:  22% (33/148)   \rReceiving objects:  23% (35/148)   \rReceiving objects:  24% (36/148)   \rReceiving objects:  25% (37/148)   \rReceiving objects:  26% (39/148)   \rReceiving objects:  27% (40/148)   \rReceiving objects:  28% (42/148)   \rReceiving objects:  29% (43/148)   \rReceiving objects:  30% (45/148)   \rReceiving objects:  31% (46/148)   \rReceiving objects:  32% (48/148)   \rReceiving objects:  33% (49/148)   \rReceiving objects:  34% (51/148)   \rReceiving objects:  35% (52/148)   \rReceiving objects:  36% (54/148)   \rReceiving objects:  37% (55/148)   \rReceiving objects:  38% (57/148)   \rReceiving objects:  39% (58/148)   \rReceiving objects:  40% (60/148)   \rReceiving objects:  41% (61/148)   \rReceiving objects:  42% (63/148)   \rReceiving objects:  43% (64/148)   \rReceiving objects:  44% (66/148)   \rReceiving objects:  45% (67/148)   \rReceiving objects:  46% (69/148)   \rReceiving objects:  47% (70/148)   \rReceiving objects:  48% (72/148)   \rReceiving objects:  49% (73/148)   \rReceiving objects:  50% (74/148)   \rReceiving objects:  51% (76/148)   \rReceiving objects:  52% (77/148)   \rReceiving objects:  53% (79/148)   \rReceiving objects:  54% (80/148)   \rReceiving objects:  55% (82/148)   \rReceiving objects:  56% (83/148)   \rReceiving objects:  57% (85/148)   \rReceiving objects:  58% (86/148)   \rReceiving objects:  59% (88/148)   \rReceiving objects:  60% (89/148)   \rReceiving objects:  61% (91/148)   \rReceiving objects:  62% (92/148)   \rReceiving objects:  63% (94/148)   \rReceiving objects:  64% (95/148)   \rReceiving objects:  65% (97/148)   \rReceiving objects:  66% (98/148)   \rReceiving objects:  67% (100/148)   \rReceiving objects:  68% (101/148)   \rReceiving objects:  69% (103/148)   \rReceiving objects:  70% (104/148)   \rReceiving objects:  71% (106/148)   \rReceiving objects:  72% (107/148)   \rReceiving objects:  73% (109/148)   \rReceiving objects:  74% (110/148)   \rReceiving objects:  75% (111/148)   \rReceiving objects:  76% (113/148)   \rReceiving objects:  77% (114/148)   \rReceiving objects:  78% (116/148)   \rReceiving objects:  79% (117/148)   \rReceiving objects:  80% (119/148)   \rReceiving objects:  81% (120/148)   \rReceiving objects:  82% (122/148)   \rReceiving objects:  83% (123/148)   \rReceiving objects:  84% (125/148)   \rReceiving objects:  85% (126/148)   \rReceiving objects:  86% (128/148)   \rReceiving objects:  87% (129/148)   \rReceiving objects:  88% (131/148)   \rReceiving objects:  89% (132/148)   \rReceiving objects:  90% (134/148)   \rReceiving objects:  91% (135/148)   \rReceiving objects:  92% (137/148)   \rReceiving objects:  93% (138/148)   \rReceiving objects:  94% (140/148)   \rReceiving objects:  95% (141/148)   \rReceiving objects:  96% (143/148)   \rremote: Total 148 (delta 7), reused 11 (delta 3), pack-reused 126\u001b[K\n",
            "Receiving objects:  97% (144/148)   \rReceiving objects:  98% (146/148)   \rReceiving objects:  99% (147/148)   \rReceiving objects: 100% (148/148)   \rReceiving objects: 100% (148/148), 220.94 KiB | 3.40 MiB/s, done.\n",
            "Resolving deltas:   0% (0/74)   \rResolving deltas:   6% (5/74)   \rResolving deltas:  12% (9/74)   \rResolving deltas:  13% (10/74)   \rResolving deltas:  17% (13/74)   \rResolving deltas:  20% (15/74)   \rResolving deltas:  21% (16/74)   \rResolving deltas:  22% (17/74)   \rResolving deltas:  25% (19/74)   \rResolving deltas:  41% (31/74)   \rResolving deltas:  44% (33/74)   \rResolving deltas:  85% (63/74)   \rResolving deltas:  89% (66/74)   \rResolving deltas:  95% (71/74)   \rResolving deltas:  97% (72/74)   \rResolving deltas:  98% (73/74)   \rResolving deltas: 100% (74/74)   \rResolving deltas: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73uLgbICFLqn",
        "colab_type": "code",
        "outputId": "1e1ce48b-3ddd-42f5-ca65-6df946b3812f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/bert-japanese/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bert-japanese\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u7vh6bzFPGL",
        "colab_type": "code",
        "outputId": "3b43732c-7b22-4058-a5d4-55423f69e038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "Receiving objects:   0% (1/333)   \rReceiving objects:   1% (4/333)   \rReceiving objects:   2% (7/333)   \rReceiving objects:   3% (10/333)   \rReceiving objects:   4% (14/333)   \rReceiving objects:   5% (17/333)   \rReceiving objects:   6% (20/333)   \rReceiving objects:   7% (24/333)   \rReceiving objects:   8% (27/333)   \rReceiving objects:   9% (30/333)   \rReceiving objects:  10% (34/333)   \rReceiving objects:  11% (37/333)   \rReceiving objects:  12% (40/333)   \rReceiving objects:  13% (44/333)   \rReceiving objects:  14% (47/333)   \rReceiving objects:  15% (50/333)   \rReceiving objects:  16% (54/333)   \rReceiving objects:  17% (57/333)   \rReceiving objects:  18% (60/333)   \rReceiving objects:  19% (64/333)   \rReceiving objects:  20% (67/333)   \rReceiving objects:  21% (70/333)   \rReceiving objects:  22% (74/333)   \rReceiving objects:  23% (77/333)   \rReceiving objects:  24% (80/333)   \rReceiving objects:  25% (84/333)   \rReceiving objects:  26% (87/333)   \rReceiving objects:  27% (90/333)   \rReceiving objects:  28% (94/333)   \rReceiving objects:  29% (97/333)   \rReceiving objects:  30% (100/333)   \rReceiving objects:  31% (104/333)   \rReceiving objects:  32% (107/333)   \rReceiving objects:  33% (110/333)   \rReceiving objects:  34% (114/333)   \rReceiving objects:  35% (117/333)   \rReceiving objects:  36% (120/333)   \rReceiving objects:  37% (124/333)   \rReceiving objects:  38% (127/333)   \rReceiving objects:  39% (130/333)   \rReceiving objects:  40% (134/333)   \rReceiving objects:  41% (137/333)   \rReceiving objects:  42% (140/333)   \rReceiving objects:  43% (144/333)   \rReceiving objects:  44% (147/333)   \rReceiving objects:  45% (150/333)   \rReceiving objects:  46% (154/333)   \rReceiving objects:  47% (157/333)   \rremote: Total 333 (delta 0), reused 0 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects:  48% (160/333)   \rReceiving objects:  49% (164/333)   \rReceiving objects:  50% (167/333)   \rReceiving objects:  51% (170/333)   \rReceiving objects:  52% (174/333)   \rReceiving objects:  53% (177/333)   \rReceiving objects:  54% (180/333)   \rReceiving objects:  55% (184/333)   \rReceiving objects:  56% (187/333)   \rReceiving objects:  57% (190/333)   \rReceiving objects:  58% (194/333)   \rReceiving objects:  59% (197/333)   \rReceiving objects:  60% (200/333)   \rReceiving objects:  61% (204/333)   \rReceiving objects:  62% (207/333)   \rReceiving objects:  63% (210/333)   \rReceiving objects:  64% (214/333)   \rReceiving objects:  65% (217/333)   \rReceiving objects:  66% (220/333)   \rReceiving objects:  67% (224/333)   \rReceiving objects:  68% (227/333)   \rReceiving objects:  69% (230/333)   \rReceiving objects:  70% (234/333)   \rReceiving objects:  71% (237/333)   \rReceiving objects:  72% (240/333)   \rReceiving objects:  73% (244/333)   \rReceiving objects:  74% (247/333)   \rReceiving objects:  75% (250/333)   \rReceiving objects:  76% (254/333)   \rReceiving objects:  77% (257/333)   \rReceiving objects:  78% (260/333)   \rReceiving objects:  79% (264/333)   \rReceiving objects:  80% (267/333)   \rReceiving objects:  81% (270/333)   \rReceiving objects:  82% (274/333)   \rReceiving objects:  83% (277/333)   \rReceiving objects:  84% (280/333)   \rReceiving objects:  85% (284/333)   \rReceiving objects:  86% (287/333)   \rReceiving objects:  87% (290/333)   \rReceiving objects:  88% (294/333)   \rReceiving objects:  89% (297/333)   \rReceiving objects:  90% (300/333)   \rReceiving objects:  91% (304/333)   \rReceiving objects:  92% (307/333)   \rReceiving objects:  93% (310/333)   \rReceiving objects:  94% (314/333)   \rReceiving objects:  95% (317/333)   \rReceiving objects:  96% (320/333)   \rReceiving objects:  97% (324/333)   \rReceiving objects:  98% (327/333)   \rReceiving objects:  99% (330/333)   \rReceiving objects: 100% (333/333)   \rReceiving objects: 100% (333/333), 282.45 KiB | 3.82 MiB/s, done.\n",
            "Resolving deltas:   0% (0/183)   \rResolving deltas:   1% (2/183)   \rResolving deltas:   2% (5/183)   \rResolving deltas:   3% (7/183)   \rResolving deltas:  11% (21/183)   \rResolving deltas:  13% (25/183)   \rResolving deltas:  15% (28/183)   \rResolving deltas:  17% (32/183)   \rResolving deltas:  18% (34/183)   \rResolving deltas:  25% (47/183)   \rResolving deltas:  26% (49/183)   \rResolving deltas:  30% (55/183)   \rResolving deltas:  39% (72/183)   \rResolving deltas:  42% (77/183)   \rResolving deltas:  46% (86/183)   \rResolving deltas:  89% (164/183)   \rResolving deltas: 100% (183/183)   \rResolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuAyfTFCFU5a",
        "colab_type": "code",
        "outputId": "ec584910-b552-4c72-e182-966307c42461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOuxLMPitaGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q -r bert-japanese/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_VWV70FrqfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWbKTBu4s8-r",
        "colab_type": "code",
        "outputId": "3da7ae78-7695-4e22-d4ea-e1a1237ad9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!gsutil cp gs://hisaka/model/wiki-ja.model /content/bert-japanese/model/\n",
        "!gsutil cp gs://hisaka/model/wiki-ja.vocab /content/bert-japanese/model/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://hisaka/model/wiki-ja.model...\n",
            "/ [1 files][786.8 KiB/786.8 KiB]                                                \n",
            "Operation completed over 1 objects/786.8 KiB.                                    \n",
            "Copying gs://hisaka/model/wiki-ja.vocab...\n",
            "/ [1 files][581.7 KiB/581.7 KiB]                                                \n",
            "Operation completed over 1 objects/581.7 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXe4KEveqeGv",
        "colab_type": "code",
        "outputId": "d3cc8f28-4539-4b51-e049-b91dcaa7bc8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/bert-japanese/notebook"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bert-japanese/notebook\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4VOeMEKqgMz",
        "colab_type": "code",
        "outputId": "fdd19cda-09c4-4c47-bfdd-b4220e411204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check-extract-features.ipynb   finetune-to-livedoor-corpus.ipynb\n",
            "check-trained-tokenizer.ipynb  pretraining.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZBoDKTsGdwa",
        "colab_type": "text"
      },
      "source": [
        "Check TPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiTrQvdWrxzR",
        "colab_type": "code",
        "outputId": "b961b8e6-7823-42dd-c705-c78a4c06a8bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.124.25.66:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3737048413475733321),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9968169853078432389),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 430901788302994980),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 709494376541634037),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1920462314763928166),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13016199878670608326),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11739130516311576058),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8112092300802901733),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4773224122509115867),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9925971761851959300),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1977434438082247194)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fIdKMrDqRZX",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "You need to put preprocessed data on your GCS bucket.  \n",
        "To create preprocessed data, follow https://github.com/yoheikikuta/bert-japanese/blob/master/notebook/finetune-to-livedoor-corpus.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mly_p24NqRaH",
        "colab_type": "text"
      },
      "source": [
        "## Finetune pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK2y8VpuqRaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_PATH = 'gs://hisaka/model/model.ckpt-1400000'  # GCS bucket\n",
        "INPUT_DATA_GCS = 'gs://hisaka/rurubu'  # GCS bucket\n",
        "FINETUNE_OUTPUT_DIR = 'gs://hisaka/rurubu/output' # GCS bucket"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s07N5EWqRaN",
        "colab_type": "code",
        "outputId": "40b989b1-f422-4949-ed21-14a0dc0f9efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "!python3 ../src/run_classifier.py \\\n",
        "  --task_name=livedoor \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --do_train=true \\\n",
        "  --do_eval=true \\\n",
        "  --data_dir={INPUT_DATA_GCS} \\\n",
        "  --model_file=../model/wiki-ja.model \\\n",
        "  --vocab_file=../model/wiki-ja.vocab \\\n",
        "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
        "  --max_seq_length=512 \\\n",
        "  --train_batch_size=64 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --num_train_epochs=10.0 \\\n",
        "  --output_dir={FINETUNE_OUTPUT_DIR}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 07:42:33.102778 140013217052544 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0828 07:42:33.105735 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:858: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0828 07:42:33.106374 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:663: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0828 07:42:33.106503 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:663: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0828 07:42:33.106885 140013217052544 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0828 07:42:33.107680 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:684: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "Loaded a trained SentencePiece model.\n",
            "W0828 07:42:35.641519 140013217052544 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0828 07:42:36.646662 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:206: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0828 07:42:37.453203 140013217052544 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5733f62488>) includes params argument, but params are not passed to Estimator.\n",
            "I0828 07:42:37.454693 140013217052544 estimator.py:209] Using config: {'_model_dir': 'gs://hisaka/rurubu/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.124.25.66:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5727742a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.124.25.66:8470', '_evaluation_master': 'grpc://10.124.25.66:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f5733f5e940>}\n",
            "I0828 07:42:37.455021 140013217052544 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "W0828 07:42:37.455749 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:362: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0828 07:42:37.456150 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:366: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0828 07:42:37.456279 140013217052544 run_classifier.py:366] Writing example 0 of 1025\n",
            "I0828 07:42:37.456752 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:37.456836 140013217052544 run_classifier.py:341] guid: train-1\n",
            "I0828 07:42:37.456922 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 天王 まつり 提 灯 を 神 前に 捧げ 男児 と 女児 が 提 灯 を 交換 する 習 わし から 、 別名 ・ 提 灯 祭 といわれる 。 [SEP]\n",
            "I0828 07:42:37.457103 140013217052544 run_classifier.py:344] input_ids: 4 9 19056 10193 17454 3909 18 242 1019 9960 22628 20 23708 12 17454 3909 18 1928 35 4104 12468 28 7 7547 13 17454 3909 1142 3864 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.457298 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.457477 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.457539 140013217052544 run_classifier.py:347] label: fire (id = 7)\n",
            "I0828 07:42:37.458751 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:37.458857 140013217052544 run_classifier.py:341] guid: train-2\n",
            "I0828 07:42:37.458961 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 伝統 文化 の 夕 べ ▁第 33 回 長良川 薪 能 清 流 長良川 と 金 華 山 、 ライト アップ された 岐阜 城 。 幻想 的な ロケーション を背景に 、 川 辺 に つくられた 特設 舞台 で 一流 能楽 師 による 能 舞台 が 繰り 広げ られる 。 鵜 飼 舟 のか が り 火 からも らい 受けた 炎 で 照らし 出される 舞台 は 、 まさに 幽 玄 の世界 。 開場 17 時 、 開 演 18 時 。 [SEP]\n",
            "I0828 07:42:37.459152 140013217052544 run_classifier.py:344] input_ids: 4 9 5007 423 10 4452 1720 581 1452 107 30037 27205 1624 596 490 30037 20 252 1638 84 7 1750 1844 53 6140 236 8 15222 132 28276 14203 7 131 2126 17 26271 16606 1190 19 19938 28549 839 71 1624 1190 12 8481 17868 1038 8 19517 11915 5080 1974 12 101 876 2811 4007 9101 2961 19 30087 10821 1190 11 7 17937 18560 3962 3304 8 24224 136 180 7 1138 4529 143 180 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.459354 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.459524 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.459587 140013217052544 run_classifier.py:347] label: Traditional-performing-arts-and-dance (id = 2)\n",
            "I0828 07:42:37.460538 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:37.460646 140013217052544 run_classifier.py:341] guid: train-3\n",
            "I0828 07:42:37.460741 140013217052544 run_classifier.py:343] tokens: [CLS] ▁天 童 夏 まつり 花 笠 踊り 、 花 駒 踊り 、 将棋 み こ し が 市内に 繰り 出す 。 8 日 ( 木 ) は 花 笠 踊り 、 9 日 ( 金 ) には 、 将棋 み こ し パレード 、 天 童 花 駒 お どり パレード が行われる 。 ▁ 画像 提供 : 天 童 夏 まつり 実行委員会 [SEP]\n",
            "I0828 07:42:37.460934 140013217052544 run_classifier.py:344] input_ids: 4 10163 6548 1080 10193 533 4629 7066 7 533 4042 7066 7 6089 206 315 32 12 13235 8481 1830 8 50 33 15 281 14 11 533 4629 7066 7 52 33 15 252 14 42 7 6089 206 315 32 13244 7 427 6548 533 4042 220 13001 13244 2934 8 9 3659 1944 76 427 6548 1080 10193 25510 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.461112 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.461305 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.461370 140013217052544 run_classifier.py:347] label: Traditional-performing-arts-and-dance (id = 2)\n",
            "I0828 07:42:37.462214 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:37.462316 140013217052544 run_classifier.py:341] guid: train-4\n",
            "I0828 07:42:37.462403 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 天神 祭 奉納 花火 年に 1 度 、 御 祭神 のお 出 ま し を祝う 奉納 花火 。 船 渡 御 などの 神 事を 盛り上げ る 。 多くの 人 出 が 予想 され 、 2 カ所 から 計 約 5000 発 を打ち 上げる 。 [SEP]\n",
            "I0828 07:42:37.462563 140013217052544 run_classifier.py:344] input_ids: 4 9 10662 1142 16418 19484 44 24 368 7 728 13649 4992 353 428 32 27004 16418 19484 8 429 1438 728 120 242 5022 26884 56 8 398 63 353 12 4371 79 7 25 22781 28 1182 198 4122 605 5895 8208 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.541751 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.542267 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.542406 140013217052544 run_classifier.py:347] label: fireworks (id = 8)\n",
            "I0828 07:42:37.544019 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:37.544139 140013217052544 run_classifier.py:341] guid: train-5\n",
            "I0828 07:42:37.544255 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 鳥取 しゃ んしゃ ん 祭 ▁第 66 回 市民 納 涼 花火大会 鳥取 市の 夏の 風 物 詩 。 最大 5 号 玉 の 花火 の 打ち上げ のほか 、 音楽 に合わせて 打ち 上がる 音楽 花火 は 必 見 。 ▁ 画像 提供 : 新 日本海 新聞社 [SEP]\n",
            "I0828 07:42:37.544431 140013217052544 run_classifier.py:344] input_ids: 4 9 10349 2874 19937 1260 1142 581 3198 107 1296 3140 6272 29807 10349 1033 6568 406 280 1787 8 1032 41 158 1188 10 19484 10 7515 2097 7 419 4650 2251 5862 419 19484 11 18255 310 8 9 3659 1944 76 123 11504 9767 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.544606 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.544907 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:37.545082 140013217052544 run_classifier.py:347] label: fireworks (id = 8)\n",
            "I0828 07:42:39.024409 140013217052544 run_classifier.py:748] ***** Running training *****\n",
            "I0828 07:42:39.024669 140013217052544 run_classifier.py:749]   Num examples = 1025\n",
            "I0828 07:42:39.024767 140013217052544 run_classifier.py:750]   Batch size = 64\n",
            "I0828 07:42:39.024821 140013217052544 run_classifier.py:751]   Num steps = 160\n",
            "W0828 07:42:39.024956 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:393: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "I0828 07:42:40.930706 140013217052544 estimator.py:360] Skipping training since max_steps has already saved.\n",
            "I0828 07:42:40.931021 140013217052544 error_handling.py:96] training_loop marked as finished\n",
            "I0828 07:42:41.734676 140013217052544 run_classifier.py:366] Writing example 0 of 344\n",
            "I0828 07:42:41.735380 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:41.735508 140013217052544 run_classifier.py:341] guid: dev-1\n",
            "I0828 07:42:41.735608 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 川内 大 綱 引 長さ 3 65 m 直径 40 cm 重さ 7 トン の大 綱 引き 。 参加者 3000 人 、 観客 は 6 万人 におよぶ 。 400 年の 往 古 を 今 に 伝える 祭典 で 、 上半身 裸 の 若者 たち が激しく ぶつ かり 合う さま は 迫 力 あり 。 [SEP]\n",
            "I0828 07:42:41.735798 140013217052544 run_classifier.py:344] input_ids: 4 9 17940 62 2028 1794 3623 31 2192 85 6185 438 418 20429 46 460 1630 2028 1635 8 7153 4606 63 7 3999 11 43 1736 27111 8 2138 223 10105 608 18 899 17 11137 23448 19 7 29766 9072 10 5838 1022 20114 11045 4418 4277 6968 11 5816 270 1054 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.735977 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.736149 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.736227 140013217052544 run_classifier.py:347] label: Traditional-Festivalsand-annual-events (id = 0)\n",
            "I0828 07:42:41.737293 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:41.737400 140013217052544 run_classifier.py:341] guid: dev-2\n",
            "I0828 07:42:41.737492 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 泉 州 ▁ 光 と 音 の 夢 花火 泉 南 市で 2018 年 、 13 年ぶりに 復活 を遂げた 大 輪 の花 が再び 泉 州の 夜 空 を 彩 る 。 目指 せ ▁2 万 5000 発 を目標に 皆 で 作り 上げる 参加 型 花火 。 音楽 に合わせて 打ち 上がる 花火 と レーザー の イ リュー ション 夢 花火 へ 。 [SEP]\n",
            "I0828 07:42:41.737652 140013217052544 run_classifier.py:344] input_ids: 4 9 1456 200 9 288 20 515 10 1392 19484 1456 191 12331 3369 16 7 166 5403 3080 17687 62 1289 8820 15768 1456 3345 1090 698 18 4460 56 8 24480 1037 892 321 4122 605 26249 5244 19 3057 8208 1058 177 19484 8 419 4650 2251 5862 19484 20 8534 10 250 4092 2525 1392 19484 90 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.737813 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.737978 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.738038 140013217052544 run_classifier.py:347] label: fireworks (id = 8)\n",
            "I0828 07:42:41.738919 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:41.739033 140013217052544 run_classifier.py:341] guid: dev-3\n",
            "I0828 07:42:41.739127 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 仙 崎 祇園 祭 19 日 ( 金 ) 、 26 日 ( 金 ) が メイン で 、 笛 、 太鼓 、 鉦 などの 賑 やかな 祇園 囃 し で 山 車が 街 なか に 繰り 出す 。 20 日 ( 土 ) には 花火大会 も 行われる ( 交通 規制 あり ) 。 [SEP]\n",
            "I0828 07:42:41.739351 140013217052544 run_classifier.py:344] input_ids: 4 9 3506 1105 20770 1142 227 33 15 252 14 7 322 33 15 252 14 12 1671 19 7 10266 7 11745 7 0 120 23180 12759 20770 31827 32 19 84 11092 1595 2610 17 8481 1830 8 110 33 15 811 14 42 29807 30 3513 15 986 2547 1054 14 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.739527 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.739696 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.739757 140013217052544 run_classifier.py:347] label: Shrine-floats-etc. (id = 1)\n",
            "I0828 07:42:41.740805 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:41.740922 140013217052544 run_classifier.py:341] guid: dev-4\n",
            "I0828 07:42:41.741029 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 全国 花火 名人 選抜 競技大会 ▁ ふく ろ い 遠 州の 花火 2019 全国 から 選抜 された 花火 名人 が 文 部 科学 大臣 賞 をかけて 競 う 「 全国 花火 名人 選抜 競技大会 」 を中心に 、「 日本一 ジャンボ ワイド マスター マイン 」「 日本一 メロディー スター マイン 」「 空中 ナイ ア ガラ 大 富士 瀑 布 」「 大 玉 100 連 発 」 など 豪華 多彩な 花火 の オン パレード となる 。 ラグビー ワールドカップ の開催 を記念し た ドラマ チック ハナ ビ が 復活 する 。 ▁ 画像 : ( c ) 泉 谷 玄 作 / ふく ろ い 遠 州の 花火 実行委員会 ▁ 提供 [SEP]\n",
            "I0828 07:42:41.741212 140013217052544 run_classifier.py:344] input_ids: 4 9 676 19484 12827 4262 17468 9 6778 1406 128 1485 3345 19484 10993 676 28 4262 53 19484 12827 12 251 126 1274 1838 436 8921 7789 307 23 676 19484 12827 4262 17468 21 888 93 11484 26221 7404 4762 12287 343 11484 21600 565 12287 343 6873 3353 88 7815 62 2915 31531 2283 343 62 1188 431 779 605 21 45 20773 17918 19484 10 1711 13244 89 8 4182 2590 8008 26773 40 1000 15840 12061 365 12 3080 35 8 9 3659 76 15 186 14 1456 433 3962 332 140 6778 1406 128 1485 3345 19484 25510 9 1944 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.741384 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.741549 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.786806 140013217052544 run_classifier.py:347] label: fireworks (id = 8)\n",
            "I0828 07:42:41.788767 140013217052544 run_classifier.py:340] *** Example ***\n",
            "I0828 07:42:41.788970 140013217052544 run_classifier.py:341] guid: dev-5\n",
            "I0828 07:42:41.789116 140013217052544 run_classifier.py:343] tokens: [CLS] ▁ 全国 こ け し 祭り こ け し 祭り コンクール 入賞 作品が 展示 される 。 全国 の伝統 こ け し の 展示 即 売 、 実演 。 8 月 30 日 ( 金 ) は 鳴 子 温泉 神社 にて こ け し 供養 祭 、 8 月 31 日 ( 土 ) の 夜 は 鳴 子 温泉 街 で お 祭り 広場 、 パレード など を実施する 。 ▁ 画像 提供 : 全国 こ け し 祭り 実行委員会 [SEP]\n",
            "I0828 07:42:41.789310 140013217052544 run_classifier.py:344] input_ids: 4 9 676 315 1068 32 5043 315 1068 32 5043 7367 14127 9140 2144 98 8 676 9821 315 1068 32 10 2144 5724 2918 7 28925 8 50 22 141 33 15 252 14 11 4546 129 1777 955 241 315 1068 32 18494 1142 7 50 22 457 33 15 811 14 10 1090 11 4546 129 1777 1595 19 220 5043 4149 7 13244 45 14700 8 9 3659 1944 76 676 315 1068 32 5043 25510 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.789484 140013217052544 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.789652 140013217052544 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:42:41.789714 140013217052544 run_classifier.py:347] label: Industry (id = 26)\n",
            "I0828 07:42:43.261763 140013217052544 run_classifier.py:775] ***** Running evaluation *****\n",
            "I0828 07:42:43.262051 140013217052544 run_classifier.py:778]   Num examples = 344 (342 actual, 2 padding)\n",
            "I0828 07:42:43.262146 140013217052544 run_classifier.py:779]   Batch size = 8\n",
            "I0828 07:42:43.262540 140013217052544 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.124.25.66:8470) for TPU system metadata.\n",
            "2019-08-28 07:42:43.264026: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "I0828 07:42:43.276630 140013217052544 tpu_system_metadata.py:148] Found TPU system:\n",
            "I0828 07:42:43.276835 140013217052544 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "I0828 07:42:43.276920 140013217052544 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "I0828 07:42:43.276980 140013217052544 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "I0828 07:42:43.277039 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3737048413475733321)\n",
            "I0828 07:42:43.277861 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 430901788302994980)\n",
            "I0828 07:42:43.277926 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 709494376541634037)\n",
            "I0828 07:42:43.277985 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1920462314763928166)\n",
            "I0828 07:42:43.278042 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13016199878670608326)\n",
            "I0828 07:42:43.278103 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11739130516311576058)\n",
            "I0828 07:42:43.278174 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8112092300802901733)\n",
            "I0828 07:42:43.278235 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4773224122509115867)\n",
            "I0828 07:42:43.278299 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9925971761851959300)\n",
            "I0828 07:42:43.278357 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1977434438082247194)\n",
            "I0828 07:42:43.278414 140013217052544 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9968169853078432389)\n",
            "I0828 07:42:43.485874 140013217052544 estimator.py:1145] Calling model_fn.\n",
            "W0828 07:42:43.508198 140013217052544 deprecation.py:323] From ../src/run_classifier.py:429: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0828 07:42:43.508545 140013217052544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0828 07:42:43.511037 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:402: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0828 07:42:43.516077 140013217052544 deprecation.py:323] From ../src/run_classifier.py:409: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0828 07:42:43.606431 140013217052544 run_classifier.py:506] *** Features ***\n",
            "I0828 07:42:43.606703 140013217052544 run_classifier.py:508]   name = input_ids, shape = (1, 512)\n",
            "I0828 07:42:43.606778 140013217052544 run_classifier.py:508]   name = input_mask, shape = (1, 512)\n",
            "I0828 07:42:43.606836 140013217052544 run_classifier.py:508]   name = is_real_example, shape = (1,)\n",
            "I0828 07:42:43.606888 140013217052544 run_classifier.py:508]   name = label_ids, shape = (1,)\n",
            "I0828 07:42:43.606940 140013217052544 run_classifier.py:508]   name = segment_ids, shape = (1, 512)\n",
            "W0828 07:42:43.607960 140013217052544 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0828 07:42:43.611443 140013217052544 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0828 07:42:43.796420 140013217052544 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0828 07:42:43.845718 140013217052544 deprecation.py:323] From /content/bert-japanese/src/../bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "I0828 07:42:47.841024 140013217052544 run_classifier.py:542] **** Trainable Variables ****\n",
            "I0828 07:42:47.841351 140013217052544 run_classifier.py:548]   name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841471 140013217052544 run_classifier.py:548]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841537 140013217052544 run_classifier.py:548]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841598 140013217052544 run_classifier.py:548]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841651 140013217052544 run_classifier.py:548]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841704 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841759 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841814 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841867 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841918 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.841969 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842019 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842072 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842121 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842183 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842237 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842296 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842345 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842397 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842447 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842494 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842543 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842594 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842643 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842693 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842740 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842794 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842844 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842894 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842943 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.842991 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843038 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843087 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843135 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843199 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843251 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843305 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843354 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843405 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843452 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843502 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843550 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843600 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843648 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843698 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843745 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843796 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843845 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843896 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843944 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.843994 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844043 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844093 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844141 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844232 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844301 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844354 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844405 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844456 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844505 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844558 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844607 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844654 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844703 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844754 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844817 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844897 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.844976 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845052 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845124 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845228 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845320 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845412 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845497 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845582 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845659 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845739 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845818 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845897 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.845976 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846070 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846176 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846288 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846385 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846479 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846576 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846678 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846771 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846873 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.846973 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847075 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847189 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847306 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847405 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847500 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847597 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847699 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847802 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.847906 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848005 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848100 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848219 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848346 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848451 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848558 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848664 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848768 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848863 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.848959 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849057 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849153 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849267 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849383 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849485 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849598 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849697 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849796 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849893 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.849995 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850095 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850214 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850328 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850435 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850534 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850631 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850728 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850835 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.850930 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851040 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851148 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851278 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851382 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851481 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851577 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851676 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851779 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851886 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.851983 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852084 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852197 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852309 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852409 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852506 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852603 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852703 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852799 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852890 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.852967 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853058 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853151 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853268 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853375 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853479 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853576 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853674 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853772 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853875 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.853970 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854058 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854175 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854289 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854387 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854491 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854589 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854683 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854790 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.854895 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855000 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855103 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855227 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855340 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855438 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855541 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855636 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855730 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855826 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.855929 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856024 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856126 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856241 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856346 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856444 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856547 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856642 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856741 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856836 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.856936 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857017 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857099 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857197 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857301 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857394 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857495 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857592 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857691 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857796 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857893 140013217052544 run_classifier.py:548]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.857991 140013217052544 run_classifier.py:548]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.858092 140013217052544 run_classifier.py:548]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:42:47.858206 140013217052544 run_classifier.py:548]   name = output_weights:0, shape = (30, 768)\n",
            "I0828 07:42:47.858331 140013217052544 run_classifier.py:548]   name = output_bias:0, shape = (30,)\n",
            "W0828 07:42:47.870787 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:535: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0828 07:42:49.537209 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:536: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0828 07:42:49.538711 140013217052544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3154: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0828 07:42:50.044116 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:565: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0828 07:42:50.059101 140013217052544 deprecation_wrapper.py:119] From ../src/run_classifier.py:567: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "I0828 07:42:51.078949 140013217052544 estimator.py:1147] Done calling model_fn.\n",
            "I0828 07:42:51.097019 140013217052544 evaluation.py:255] Starting evaluation at 2019-08-28T07:42:51Z\n",
            "I0828 07:42:51.097325 140013217052544 tpu_estimator.py:499] TPU job name worker\n",
            "W0828 07:42:51.223025 140013217052544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0828 07:42:51.615760 140013217052544 monitored_session.py:240] Graph was finalized.\n",
            "W0828 07:42:51.616564 140013217052544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0828 07:42:51.816640 140013217052544 saver.py:1280] Restoring parameters from gs://hisaka/rurubu/output/model.ckpt-160\n",
            "I0828 07:42:53.673145 140013217052544 session_manager.py:500] Running local_init_op.\n",
            "I0828 07:42:53.869541 140013217052544 session_manager.py:502] Done running local_init_op.\n",
            "W0828 07:42:54.148668 140013217052544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:792: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "I0828 07:42:54.348808 140013217052544 tpu_estimator.py:557] Init TPU system\n",
            "I0828 07:43:02.081321 140013217052544 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
            "I0828 07:43:02.083049 140012199450368 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0828 07:43:02.083455 140012191057664 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0828 07:43:02.306713 140013217052544 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0828 07:43:02.493086 140013217052544 tpu_estimator.py:590] Enqueue next (43) batch(es) of data to infeed.\n",
            "I0828 07:43:02.494082 140013217052544 tpu_estimator.py:594] Dequeue next (43) batch(es) of data from outfeed.\n",
            "I0828 07:43:07.793130 140012191057664 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0828 07:43:08.217366 140013217052544 evaluation.py:167] Evaluation [43/43]\n",
            "I0828 07:43:08.217734 140013217052544 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0828 07:43:08.217819 140013217052544 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0828 07:43:08.217988 140012199450368 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0828 07:43:08.218058 140012199450368 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0828 07:43:08.218413 140013217052544 error_handling.py:96] infeed marked as finished\n",
            "I0828 07:43:08.218525 140013217052544 tpu_estimator.py:602] Stop output thread controller\n",
            "I0828 07:43:08.218586 140013217052544 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0828 07:43:08.218693 140012191057664 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0828 07:43:08.218751 140012191057664 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0828 07:43:08.218856 140013217052544 error_handling.py:96] outfeed marked as finished\n",
            "I0828 07:43:08.218912 140013217052544 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0828 07:43:08.811257 140013217052544 evaluation.py:275] Finished evaluation at 2019-08-28-07:43:08\n",
            "I0828 07:43:08.811604 140013217052544 estimator.py:2039] Saving dict for global step 160: eval_accuracy = 0.7163743, eval_loss = 1.1656752, global_step = 160, loss = 1.125182\n",
            "I0828 07:43:12.542683 140013217052544 estimator.py:2099] Saving 'checkpoint_path' summary for global step 160: gs://hisaka/rurubu/output/model.ckpt-160\n",
            "I0828 07:43:13.630131 140013217052544 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0828 07:43:13.630555 140013217052544 run_classifier.py:800] ***** Eval results *****\n",
            "I0828 07:43:13.630660 140013217052544 run_classifier.py:802]   eval_accuracy = 0.7163743\n",
            "I0828 07:43:13.630965 140013217052544 run_classifier.py:802]   eval_loss = 1.1656752\n",
            "I0828 07:43:13.631102 140013217052544 run_classifier.py:802]   global_step = 160\n",
            "I0828 07:43:13.631205 140013217052544 run_classifier.py:802]   loss = 1.125182\n",
            "CPU times: user 374 ms, sys: 55.8 ms, total: 429 ms\n",
            "Wall time: 50.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhEPDllLqRaU",
        "colab_type": "text"
      },
      "source": [
        "## Predict using the finetuned model\n",
        "\n",
        "Let's predict test data using the finetuned model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYmG1srRxT7U",
        "colab_type": "code",
        "outputId": "b44f7528-f430-48c8-f60a-1b3de4a24a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "!python3 ../src/run_classifier.py \\\n",
        "  --task_name=livedoor \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --do_train=false \\\n",
        "  --do_eval=false \\\n",
        "  --do_predict=true \\\n",
        "  --data_dir={INPUT_DATA_GCS} \\\n",
        "  --model_file=../model/wiki-ja.model \\\n",
        "  --vocab_file=../model/wiki-ja.vocab \\\n",
        "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
        "  --max_seq_length=512 \\\n",
        "  --train_batch_size=64 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --num_train_epochs=3.0 \\\n",
        "  --output_dir={FINETUNE_OUTPUT_DIR}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 07:44:14.993865 140251878299520 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0828 07:44:14.997009 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:858: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0828 07:44:14.997752 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:663: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0828 07:44:14.997915 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:663: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0828 07:44:14.998378 140251878299520 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0828 07:44:14.999205 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:684: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "Loaded a trained SentencePiece model.\n",
            "W0828 07:44:17.538808 140251878299520 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0828 07:44:18.544819 140251878299520 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8eb8d911e0>) includes params argument, but params are not passed to Estimator.\n",
            "I0828 07:44:18.546437 140251878299520 estimator.py:209] Using config: {'_model_dir': 'gs://hisaka/rurubu/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.124.25.66:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8eb8dad3c8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.124.25.66:8470', '_evaluation_master': 'grpc://10.124.25.66:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f8ec5477908>}\n",
            "I0828 07:44:18.546795 140251878299520 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "W0828 07:44:18.547539 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:206: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0828 07:44:19.389999 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:362: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0828 07:44:19.390623 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:366: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0828 07:44:19.390772 140251878299520 run_classifier.py:366] Writing example 0 of 344\n",
            "I0828 07:44:19.391471 140251878299520 run_classifier.py:340] *** Example ***\n",
            "I0828 07:44:19.391580 140251878299520 run_classifier.py:341] guid: test-1\n",
            "I0828 07:44:19.391705 140251878299520 run_classifier.py:343] tokens: [CLS] ▁ アーク ヒルズ 秋 祭り 2019 周辺には 大使館 等が 集積 する 国際 色 豊かな エリア でありながら 、 日本の 和 の 心 と 季節 を 感じられる 祭り となっている 。 秋 祭り 内容は 、 盆 踊り 、 縁 日 屋台 ・ グルメ 屋台 、 子ども 神輿 と 山 車 、 休憩 スペース 、 ワークショップ 、 パフォーマンス など を行う 予定 。 [SEP]\n",
            "I0828 07:44:19.391930 140251878299520 run_classifier.py:344] input_ids: 4 9 12684 16850 1425 5043 10993 19080 9224 9329 12969 35 420 502 9180 2589 8650 7 216 330 10 509 20 7934 18 30410 5043 207 8 1425 5043 5165 7 16100 7066 7 1540 33 21116 13 22180 21116 7 5881 25250 20 84 304 7 18786 3115 7 24678 7 5086 45 435 1401 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.392123 140251878299520 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.392315 140251878299520 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.392387 140251878299520 run_classifier.py:347] label: festival (id = 15)\n",
            "I0828 07:44:19.393671 140251878299520 run_classifier.py:340] *** Example ***\n",
            "I0828 07:44:19.393782 140251878299520 run_classifier.py:341] guid: test-2\n",
            "I0828 07:44:19.393912 140251878299520 run_classifier.py:343] tokens: [CLS] ▁ 秋田 竿 燈 まつり 豊 作 祈願 と 病 魔 を 祓 う 、 ね ぶり 流し 行事 が 結び ついた 祭り 。 12 m 余り の 竹 に 9 本の 横 竹 を結び 、 46 個の 提 灯 を 吊 した 50 kg もの 竿 燈 を 手の ひら 、 額 、 肩 、 腰 に バランス を取り ながら の せ ていく 。 竿 燈 大通り の中央 に設けられた 観覧 席 からの 眺め は 格 別 で 、 ゆっくり と 竿 燈 の 妙 技 が見られる 。 ▁ 画像 提供 : 秋田 市 竿 燈 まつり 実行委員会 [SEP]\n",
            "I0828 07:44:19.394439 140251878299520 run_classifier.py:344] input_ids: 4 9 4196 29320 19615 10193 1311 332 18313 20 1114 2824 18 29991 307 7 969 3213 17743 5887 12 6212 7458 5043 8 66 85 7161 10 1557 17 52 2737 894 1557 11478 7 1800 3622 17454 3909 18 20464 29 413 1281 375 29320 19615 18 12210 8410 7 1433 7 4026 7 4910 17 6927 2173 527 10 1037 2199 8 29320 19615 21606 12346 17652 23728 1321 440 19970 11 1755 519 19 7 17752 20 29320 19615 10 4095 1384 3688 8 9 3659 1944 76 4196 69 29320 19615 10193 25510 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.394707 140251878299520 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.394951 140251878299520 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.395043 140251878299520 run_classifier.py:347] label: fire (id = 7)\n",
            "I0828 07:44:19.396123 140251878299520 run_classifier.py:340] *** Example ***\n",
            "I0828 07:44:19.396261 140251878299520 run_classifier.py:341] guid: test-3\n",
            "I0828 07:44:19.396393 140251878299520 run_classifier.py:343] tokens: [CLS] ▁ 赤 湯 温泉 ふるさと 祭り 地区 を挙げて の 一大 イベント 。 初日 の 男 ・ 女 神輿 、 中学生 本 神輿 三 基 による 競 演 と 、 2 日目 の 暴れ 獅子 太鼓 に 鼓 舞 された 若者 獅子 の も み 合い で 、 温泉 街 は 祭り ムード 一色 となる 。 初日 の 見 頃 は 18 ～ 21 時 、 2 日目 は 19 ～ 22 時 ごろ 。 [SEP]\n",
            "I0828 07:44:19.396607 140251878299520 run_classifier.py:344] input_ids: 4 9 817 1881 1777 18232 5043 452 21103 10 20107 906 8 15435 10 629 13 612 25250 7 9038 96 25250 171 857 71 7789 4529 20 7 25 8065 10 24421 13140 11745 17 15194 3062 53 5838 13140 10 30 206 2878 19 7 1777 1595 11 5043 27236 16834 89 8 15435 10 310 1975 11 143 528 253 180 7 25 8065 11 227 528 291 180 6958 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.396816 140251878299520 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.397018 140251878299520 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.397099 140251878299520 run_classifier.py:347] label: Shrine-floats-etc. (id = 1)\n",
            "I0828 07:44:19.398330 140251878299520 run_classifier.py:340] *** Example ***\n",
            "I0828 07:44:19.398440 140251878299520 run_classifier.py:341] guid: test-4\n",
            "I0828 07:44:19.398581 140251878299520 run_classifier.py:343] tokens: [CLS] ▁ 明石 海峡 大橋 ライト アップ 明石 海峡 大橋 では 、 世界で初めて 色 を 自在 に 演出 できる ケーブル 照明 を 設置 。 照明 による ケーブル 曲線 美 を 表現 できるように した イル ミ ネーション を 毎日 行っている 。 神戸 ル ミナ リエ の 開始 に合わせて 、 赤 や 緑 を主 とした クリスマス カラー の パターン で ライト アップ を行い 、 クリスマス ムード を 盛り上げ る 。 車 では 淡路 sa から 眺め る の が お すすめ 。 12 月 29 日 ( 土 ) からは 赤 一色 の 年末 パターン を 点灯 する 。 12 月 31 日 ( 月 ) は 23 時 30 分 より 新 年 への カウントダウン パターン を 点灯 し 、 日の 出 まで 点灯 。 [SEP]\n",
            "I0828 07:44:19.398811 140251878299520 run_classifier.py:344] input_ids: 4 9 12099 5000 5702 1750 1844 12099 5000 5702 38 7 26969 502 18 24636 17 2425 355 7263 9187 18 1299 8 9187 71 7263 7125 400 18 1030 9127 29 2543 318 18853 18 4563 7753 8 2035 179 9573 5954 10 1163 4650 7 817 26 2571 7722 611 7257 2156 10 4957 19 1750 1844 897 7 7257 27236 18 26884 56 8 304 38 17351 1854 28 19970 56 10 12 220 22050 8 66 22 362 33 15 811 14 994 817 16834 10 8329 4957 18 22687 35 8 66 22 457 33 15 22 14 11 294 180 141 152 94 123 16 105 28912 4957 18 22687 32 7 454 353 109 22687 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.399019 140251878299520 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.468683 140251878299520 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.468992 140251878299520 run_classifier.py:347] label: illumination (id = 10)\n",
            "I0828 07:44:19.471052 140251878299520 run_classifier.py:340] *** Example ***\n",
            "I0828 07:44:19.471254 140251878299520 run_classifier.py:341] guid: test-5\n",
            "I0828 07:44:19.471394 140251878299520 run_classifier.py:343] tokens: [CLS] ▁ 赤 崎 まつり ( 南 条 踊 と 楽 踊 ) 15 日に 山口県 無 形 民俗 文化財 に指定されている 湯 本 南 条 踊 、 赤 崎 神社 楽 踊 が 奉納 され 、 14 日の 前夜 祭 には 夜 店 も 出る 。 駐車場 が少ない ため 、 なるべく 公共交通機関 を 利用 。 また 、 赤 崎 山 周辺は 無 断 駐車 、 路上 駐車 禁止 となっている 。 [SEP]\n",
            "I0828 07:44:19.471639 140251878299520 run_classifier.py:344] input_ids: 4 9 817 1105 10193 15 191 702 15944 20 1094 15944 14 118 67 7075 383 237 15806 7378 5876 1881 96 191 702 15944 7 817 1105 955 1094 15944 12 16418 79 7 163 454 26618 1142 42 1090 568 30 8004 8 6298 6805 97 7 26450 26641 18 1002 8 240 7 817 1105 84 17416 383 1514 26334 7 19604 26334 2695 207 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.471862 140251878299520 run_classifier.py:345] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.472085 140251878299520 run_classifier.py:346] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0828 07:44:19.472193 140251878299520 run_classifier.py:347] label: Traditional-performing-arts-and-dance (id = 2)\n",
            "I0828 07:44:20.547401 140251878299520 run_classifier.py:821] ***** Running prediction*****\n",
            "I0828 07:44:20.547687 140251878299520 run_classifier.py:824]   Num examples = 344 (341 actual, 3 padding)\n",
            "I0828 07:44:20.547766 140251878299520 run_classifier.py:825]   Batch size = 8\n",
            "W0828 07:44:20.547922 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:393: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "I0828 07:44:20.548081 140251878299520 run_classifier.py:839] ***** Predict results *****\n",
            "I0828 07:44:21.170045 140251878299520 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.124.25.66:8470) for TPU system metadata.\n",
            "2019-08-28 07:44:21.171076: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "I0828 07:44:21.183377 140251878299520 tpu_system_metadata.py:148] Found TPU system:\n",
            "I0828 07:44:21.183629 140251878299520 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "I0828 07:44:21.183704 140251878299520 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "I0828 07:44:21.183750 140251878299520 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "I0828 07:44:21.183794 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3737048413475733321)\n",
            "I0828 07:44:21.184669 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 430901788302994980)\n",
            "I0828 07:44:21.184732 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 709494376541634037)\n",
            "I0828 07:44:21.184778 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1920462314763928166)\n",
            "I0828 07:44:21.184821 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13016199878670608326)\n",
            "I0828 07:44:21.184861 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11739130516311576058)\n",
            "I0828 07:44:21.184901 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8112092300802901733)\n",
            "I0828 07:44:21.184941 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4773224122509115867)\n",
            "I0828 07:44:21.184980 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9925971761851959300)\n",
            "I0828 07:44:21.185018 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1977434438082247194)\n",
            "I0828 07:44:21.185069 140251878299520 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9968169853078432389)\n",
            "I0828 07:44:21.186635 140251878299520 estimator.py:1145] Calling model_fn.\n",
            "W0828 07:44:21.209113 140251878299520 deprecation.py:323] From ../src/run_classifier.py:429: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0828 07:44:21.209389 140251878299520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0828 07:44:21.211002 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:402: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0828 07:44:21.216494 140251878299520 deprecation.py:323] From ../src/run_classifier.py:409: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0828 07:44:21.559640 140251878299520 run_classifier.py:506] *** Features ***\n",
            "I0828 07:44:21.559962 140251878299520 run_classifier.py:508]   name = input_ids, shape = (1, 512)\n",
            "I0828 07:44:21.560089 140251878299520 run_classifier.py:508]   name = input_mask, shape = (1, 512)\n",
            "I0828 07:44:21.560211 140251878299520 run_classifier.py:508]   name = is_real_example, shape = (1,)\n",
            "I0828 07:44:21.560300 140251878299520 run_classifier.py:508]   name = label_ids, shape = (1,)\n",
            "I0828 07:44:21.560412 140251878299520 run_classifier.py:508]   name = segment_ids, shape = (1, 512)\n",
            "W0828 07:44:21.561937 140251878299520 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0828 07:44:21.564306 140251878299520 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0828 07:44:21.598102 140251878299520 deprecation_wrapper.py:119] From /content/bert-japanese/src/../bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0828 07:44:21.650646 140251878299520 deprecation.py:323] From /content/bert-japanese/src/../bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "I0828 07:44:25.765423 140251878299520 run_classifier.py:542] **** Trainable Variables ****\n",
            "I0828 07:44:25.765727 140251878299520 run_classifier.py:548]   name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.765845 140251878299520 run_classifier.py:548]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.765922 140251878299520 run_classifier.py:548]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.765984 140251878299520 run_classifier.py:548]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766040 140251878299520 run_classifier.py:548]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766093 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766155 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766223 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766276 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766324 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766375 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766426 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766479 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766527 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766576 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766624 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766675 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766724 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766775 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766823 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766871 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766920 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.766971 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767019 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767071 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767126 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767191 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767244 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767297 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767345 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767391 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767438 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767489 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767539 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767597 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767644 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767692 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767739 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767789 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767837 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767888 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767936 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.767997 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768049 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768100 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768154 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768223 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768271 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768323 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768372 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768422 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768470 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768517 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768566 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768616 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768664 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768714 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768762 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768812 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768860 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768910 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.768957 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769003 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769052 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769103 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769172 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769228 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769278 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769326 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769376 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769426 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769473 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769525 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769572 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769623 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769672 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769724 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769772 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769819 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769867 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769918 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.769966 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770017 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770065 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770117 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770177 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770231 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770279 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770330 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770378 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770429 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770477 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770526 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770574 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770623 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770671 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770722 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770769 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770820 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770867 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770915 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.770963 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771013 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771062 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771118 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771178 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771233 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771281 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771333 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771381 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771428 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771477 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771529 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771578 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771631 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771680 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771727 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771777 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771827 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771876 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.771929 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.854499 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.854883 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855028 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855130 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855308 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855419 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855521 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855628 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855729 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855833 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.855937 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856035 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856133 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856270 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856374 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856478 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856581 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856702 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856803 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.856910 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857012 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857111 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857244 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857360 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857462 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857566 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857675 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857775 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857873 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.857987 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858089 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858207 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858309 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858414 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858512 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858619 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858721 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858819 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.858915 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859017 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859116 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859234 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859336 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859435 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859532 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859642 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859743 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859845 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.859942 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860044 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860144 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860265 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860363 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860460 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860559 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860670 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860786 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860894 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.860994 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861092 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861208 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861318 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861417 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861523 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861629 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861733 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861834 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.861939 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862036 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862133 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862254 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862357 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862454 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862559 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862666 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862764 140251878299520 run_classifier.py:548]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862859 140251878299520 run_classifier.py:548]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.862965 140251878299520 run_classifier.py:548]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0828 07:44:25.863062 140251878299520 run_classifier.py:548]   name = output_weights:0, shape = (30, 768)\n",
            "I0828 07:44:25.863181 140251878299520 run_classifier.py:548]   name = output_bias:0, shape = (30,)\n",
            "W0828 07:44:25.880408 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:535: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0828 07:44:27.531609 140251878299520 deprecation_wrapper.py:119] From ../src/run_classifier.py:536: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "I0828 07:44:28.099314 140251878299520 estimator.py:1147] Done calling model_fn.\n",
            "I0828 07:44:28.104017 140251878299520 tpu_estimator.py:499] TPU job name worker\n",
            "W0828 07:44:28.227127 140251878299520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0828 07:44:28.621962 140251878299520 monitored_session.py:240] Graph was finalized.\n",
            "W0828 07:44:28.622832 140251878299520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0828 07:44:28.810215 140251878299520 saver.py:1280] Restoring parameters from gs://hisaka/rurubu/output/model.ckpt-160\n",
            "I0828 07:44:30.618285 140251878299520 session_manager.py:500] Running local_init_op.\n",
            "I0828 07:44:30.811403 140251878299520 session_manager.py:502] Done running local_init_op.\n",
            "W0828 07:44:31.099991 140251878299520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:808: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "I0828 07:44:31.295726 140251878299520 tpu_estimator.py:557] Init TPU system\n",
            "I0828 07:44:40.728987 140251878299520 tpu_estimator.py:566] Initialized TPU in 9 seconds\n",
            "I0828 07:44:40.730599 140250863843072 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0828 07:44:40.730977 140250855450368 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0828 07:44:41.018863 140251878299520 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0828 07:44:41.208129 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:41.209213 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:41.210563 140250855450368 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0828 07:44:46.664582 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.664869 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.673352 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.673563 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.679877 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.680052 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.684311 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.684462 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.693717 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.693876 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.703368 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.703559 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.714262 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.714443 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.722400 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.722631 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.732097 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.732304 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.741523 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.741692 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.750938 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.751120 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.760874 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.761057 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.770488 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.770672 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.780095 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.780298 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.788796 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.788967 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.799293 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.799476 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.809023 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.809278 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.818481 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.818701 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.827923 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.828175 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.837527 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.837755 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.847582 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.847781 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.856928 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.857193 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.865535 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.865744 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.875696 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.875898 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.884811 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.884989 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.894751 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.894943 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.904432 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.904653 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.914683 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.914897 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.924543 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.924768 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.933688 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.933877 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.943403 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.943611 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.952801 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.953025 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.962205 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.962399 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.971533 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.971727 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.981127 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.981362 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:46.990529 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:46.990715 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:47.001140 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:47.001387 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:47.009582 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:47.009788 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:47.019242 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:47.019452 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:47.029193 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:47.029403 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:47.039142 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:47.039383 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:47.048373 140251878299520 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0828 07:44:47.048550 140251878299520 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0828 07:44:48.278876 140251878299520 error_handling.py:96] prediction_loop marked as finished\n",
            "CPU times: user 250 ms, sys: 44.4 ms, total: 294 ms\n",
            "Wall time: 37.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKA6AgKZE6jg",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bCQcYvoDLaw",
        "colab_type": "text"
      },
      "source": [
        "Download result and original data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLYcxd1ox5bq",
        "colab_type": "code",
        "outputId": "0c06a49e-acc1-422e-db0f-5dc1701d0ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!gsutil cp {FINETUNE_OUTPUT_DIR}/test_results.tsv .\n",
        "!gsutil cp {INPUT_DATA_GCS}/train.tsv .\n",
        "!gsutil cp {INPUT_DATA_GCS}/dev.tsv .\n",
        "!gsutil cp {INPUT_DATA_GCS}/test.tsv ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://hisaka/rurubu/output/test_results.tsv...\n",
            "/ [1 files][127.1 KiB/127.1 KiB]                                                \n",
            "Operation completed over 1 objects/127.1 KiB.                                    \n",
            "Copying gs://hisaka/rurubu/train.tsv...\n",
            "/ [1 files][382.5 KiB/382.5 KiB]                                                \n",
            "Operation completed over 1 objects/382.5 KiB.                                    \n",
            "Copying gs://hisaka/rurubu/dev.tsv...\n",
            "/ [1 files][126.8 KiB/126.8 KiB]                                                \n",
            "Operation completed over 1 objects/126.8 KiB.                                    \n",
            "Copying gs://hisaka/rurubu/test.tsv...\n",
            "/ [1 files][128.6 KiB/128.6 KiB]                                                \n",
            "Operation completed over 1 objects/128.6 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZAuB7s0Dbo2",
        "colab_type": "text"
      },
      "source": [
        "### Trained model\n",
        "\n",
        "Check accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhoM3SJ0Js1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weZ9KlSXgGCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"../src\")\n",
        "\n",
        "from run_classifier import LivedoorProcessor\n",
        "\n",
        "processor = LivedoorProcessor()\n",
        "label_list = processor.get_labels()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhccEqvTx5nO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.read_csv(\"./test_results.tsv\", sep='\\t', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn-IKJrtx5sB",
        "colab_type": "code",
        "outputId": "ef228d0a-b489-4cda-aa77-ca942e750aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "result.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.052373</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>0.833535</td>\n",
              "      <td>0.005609</td>\n",
              "      <td>0.003961</td>\n",
              "      <td>0.005431</td>\n",
              "      <td>0.009859</td>\n",
              "      <td>0.021627</td>\n",
              "      <td>0.006582</td>\n",
              "      <td>0.003966</td>\n",
              "      <td>0.001868</td>\n",
              "      <td>0.001484</td>\n",
              "      <td>0.002977</td>\n",
              "      <td>0.000803</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.001807</td>\n",
              "      <td>0.001723</td>\n",
              "      <td>0.000982</td>\n",
              "      <td>0.000834</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>0.000832</td>\n",
              "      <td>0.001310</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.001049</td>\n",
              "      <td>0.001252</td>\n",
              "      <td>0.003784</td>\n",
              "      <td>0.001659</td>\n",
              "      <td>0.003141</td>\n",
              "      <td>0.006987</td>\n",
              "      <td>0.000681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.593637</td>\n",
              "      <td>0.012734</td>\n",
              "      <td>0.105572</td>\n",
              "      <td>0.008785</td>\n",
              "      <td>0.009416</td>\n",
              "      <td>0.012685</td>\n",
              "      <td>0.027248</td>\n",
              "      <td>0.130120</td>\n",
              "      <td>0.018779</td>\n",
              "      <td>0.008833</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.002721</td>\n",
              "      <td>0.008923</td>\n",
              "      <td>0.001346</td>\n",
              "      <td>0.001611</td>\n",
              "      <td>0.003647</td>\n",
              "      <td>0.002625</td>\n",
              "      <td>0.001287</td>\n",
              "      <td>0.001639</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>0.001493</td>\n",
              "      <td>0.002509</td>\n",
              "      <td>0.001127</td>\n",
              "      <td>0.001011</td>\n",
              "      <td>0.001646</td>\n",
              "      <td>0.013223</td>\n",
              "      <td>0.003490</td>\n",
              "      <td>0.002919</td>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.001042</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        27        28        29\n",
              "0  0.052373  0.021417  0.833535  ...  0.003141  0.006987  0.000681\n",
              "1  0.593637  0.012734  0.105572  ...  0.002919  0.010230  0.001042\n",
              "\n",
              "[2 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T4jup_cqRa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(\"./test.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awsr4Uk9qRa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['predict'] = [ label_list[np.array(elem[1]).argmax()] for elem in result.iterrows() ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsKCv67CqRa-",
        "colab_type": "code",
        "outputId": "0a3f773d-28b2-41b6-9d2b-6b449dcf3f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5806451612903226"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKPg0BYtwDO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FjTB439N3lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.to_csv('./test20190828.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPofIal0qRbA",
        "colab_type": "text"
      },
      "source": [
        "A littel more detailed check using `sklearn.metrics`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWB0hihAqRbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfLBM1QaqRbK",
        "colab_type": "code",
        "outputId": "8326633c-a94d-4dd0-ae1e-a1503a45459b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "print(classification_report(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                        precision    recall  f1-score   support\n",
            "\n",
            "                   Agricultural ritual       0.00      0.00      0.00         2\n",
            "                 Procession-and-parade       0.00      0.00      0.00         9\n",
            "                    Shrine-floats-etc.       0.00      0.00      0.00        44\n",
            "Traditional-Festivalsand-annual-events       0.39      0.76      0.52        51\n",
            " Traditional-performing-arts-and-dance       0.58      0.74      0.65        62\n",
            "                                animal       0.00      0.00      0.00         1\n",
            "                              festival       0.00      0.00      0.00         2\n",
            "                                  fire       0.20      0.06      0.09        35\n",
            "                             fireworks       0.79      0.98      0.87       108\n",
            "                         flower-nature       0.11      0.50      0.18         2\n",
            "                                  food       0.00      0.00      0.00         7\n",
            "                          illumination       0.80      0.80      0.80         5\n",
            "                                market       0.00      0.00      0.00         3\n",
            "                                 music       0.00      0.00      0.00         4\n",
            "                                 other       0.00      0.00      0.00         6\n",
            "                                sports       0.00      0.00      0.00         0\n",
            "\n",
            "                              accuracy                           0.58       341\n",
            "                             macro avg       0.18      0.24      0.19       341\n",
            "                          weighted avg       0.45      0.58      0.49       341\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqQJCOJvwIbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# print(classification_report(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ilx2v3_qRbN",
        "colab_type": "code",
        "outputId": "7bbf689b-13df-4ec6-988f-ce82fcf2cf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "print(confusion_matrix(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  3  3  0  0  0  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 19 14  8  0  0  3  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  3 39  2  0  0  4  2  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  6 13 37  0  0  4  1  0  0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0]\n",
            " [ 0  2  5  8  1  0  0 17  1  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  3  3  0  0  1  2 93  2  0  2  1  0  1  0  0]\n",
            " [ 0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  1  1  0  1  1  0  1  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  0  0  0  0  0  0  0  2  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0  1]\n",
            " [ 0  0  0  1  0  0  2  1  0  0  0  1  0  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uclnr666wKNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# print(confusion_matrix(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNGkY-KRqRbS",
        "colab_type": "text"
      },
      "source": [
        "### Simple baseline model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGt3notoqRbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7bqEUJuqRbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"./train.tsv\", sep='\\t')\n",
        "dev_df = pd.read_csv(\"./dev.tsv\", sep='\\t')\n",
        "test_df = pd.read_csv(\"./test.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyq6TzksqRbV",
        "colab_type": "code",
        "outputId": "650843b9-aca9-4e5a-ebe4-b9f106a07af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get -q install -y mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  libmecab2 mecab-utils\n",
            "The following NEW packages will be installed:\n",
            "  libmecab-dev libmecab2 mecab mecab-ipadic mecab-ipadic-utf8 mecab-utils\n",
            "0 upgraded, 6 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 12.8 MB of archives.\n",
            "After this operation, 60.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 12.8 MB in 2s (7,800 kB/s)\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "(Reading database ... 131183 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../1-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../2-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../3-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../4-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../5-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPFpytOMqRbY",
        "colab_type": "code",
        "outputId": "a121363d-0734-49a2-a914-28361cbd4d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install -q mecab-python3==0.7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▉                        | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.4MB/s \n",
            "\u001b[?25h  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llc5aXZvqRbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import MeCab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CSVpKjqqRbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = MeCab.Tagger(\"-Owakati\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDv-JvWNqRbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dev_df = pd.concat([train_df, dev_df])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW1QDtRmqRbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dev_xs = train_dev_df['text'].apply(lambda x: m.parse(x))\n",
        "train_dev_ys = train_dev_df['label']\n",
        "\n",
        "test_xs = test_df['text'].apply(lambda x: m.parse(x))\n",
        "test_ys = test_df['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwdR0UwoqRbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=750)\n",
        "train_dev_xs_ = vectorizer.fit_transform(train_dev_xs)\n",
        "test_xs_ = vectorizer.transform(test_xs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P5zw9RdE0qX",
        "colab_type": "text"
      },
      "source": [
        "The following set up is not exactly identical to that of BERT because inside Classifier it uses `train_test_split` with shuffle.  \n",
        "In addition, parameters are not well tuned, however, we think it's enough to check the power of BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ_qr_Bzwea8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "model = GradientBoostingClassifier(n_estimators=200,\n",
        "                                   validation_fraction=len(dev_df)/len(train_df),\n",
        "                                   n_iter_no_change=5,\n",
        "                                   tol=0.01,\n",
        "                                   random_state=23)\n",
        "\n",
        "### 1/5 of full training data.\n",
        "# model = GradientBoostingClassifier(n_estimators=200,\n",
        "#                                    validation_fraction=len(train_df)/len(dev_df),\n",
        "#                                    n_iter_no_change=5,\n",
        "#                                    tol=0.01,\n",
        "#                                    random_state=23)\n",
        "\n",
        "model.fit(train_dev_xs_, train_dev_ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQLcNADBqRbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqKLsXi6wsSt",
        "colab_type": "code",
        "outputId": "9e233d1f-bf0b-4f30-dc1f-887e64a14272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# print(classification_report(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.82      0.71      0.76       178\n",
            "  it-life-hack       0.86      0.88      0.87       172\n",
            " kaden-channel       0.91      0.87      0.89       176\n",
            "livedoor-homme       0.67      0.63      0.65        95\n",
            "   movie-enter       0.87      0.95      0.91       158\n",
            "        peachy       0.70      0.78      0.73       174\n",
            "          smax       1.00      1.00      1.00       167\n",
            "  sports-watch       0.87      0.95      0.91       190\n",
            "    topic-news       0.92      0.82      0.87       163\n",
            "\n",
            "     micro avg       0.85      0.85      0.85      1473\n",
            "     macro avg       0.85      0.84      0.84      1473\n",
            "  weighted avg       0.86      0.85      0.85      1473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsDhUVhKqRb1",
        "colab_type": "code",
        "outputId": "c9bf78b5-c500-4eba-dde6-67a67eccb2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(confusion_matrix(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[153   4   1   4   2  13   0   1   0]\n",
            " [  3 155   6   3   0   1   0   2   2]\n",
            " [  0   5 165   0   2   0   1   1   2]\n",
            " [  3   4   6  70   4   6   0   1   1]\n",
            " [  1   0   1   3 152   1   0   0   0]\n",
            " [  7   1   1   2   3 160   0   0   0]\n",
            " [  0   0   0   0   0   0 167   0   0]\n",
            " [  1   0   0   2   0   0   0 186   1]\n",
            " [  3   1   3   5   0   3   0   8 140]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgQYajIXwtwK",
        "colab_type": "code",
        "outputId": "f1b696a9-3a26-48d3-8098-8e7887f709e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "### 1/5 of full training data.\n",
        "# print(confusion_matrix(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[127   6   1   4   5  29   0   5   1]\n",
            " [  2 152   6   7   1   2   0   1   1]\n",
            " [  1   8 153   4   5   3   0   1   1]\n",
            " [  3   7   3  60   3  15   0   2   2]\n",
            " [  1   0   1   1 150   5   0   0   0]\n",
            " [ 15   3   0  10   8 135   0   2   1]\n",
            " [  0   0   0   0   0   0 167   0   0]\n",
            " [  1   0   2   0   0   1   0 181   5]\n",
            " [  5   0   2   3   0   4   0  15 134]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2IdnG6mqRb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}